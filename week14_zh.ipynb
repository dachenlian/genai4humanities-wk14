{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44563558",
   "metadata": {},
   "source": [
    "# Week 14：檢索增強生成（RAG）、工具呼叫與結構化輸出\n",
    "\n",
    "你好！在本週的實驗課程中，我們將探索一些強大的技術，來擴展大型語言模型（LLM）的功能。我們將會學到：\n",
    "\n",
    "1.  **嵌入（Embeddings）**:\n",
    "    * 了解如何使用 `sentence-transformers` 和 OpenAI API 來將文字轉換為向量表示（嵌入）。\n",
    "    * 計算文字之間的相似度。\n",
    "2.  **向量資料庫（Vector Databases）**:\n",
    "    * 使用 LanceDB 來儲存和檢索我們產生的嵌入。\n",
    "    * 了解如何有效地查詢向量資料庫以找到相關資訊。\n",
    "3.  **檢索增強生成（Retrieval Augmented Generation - RAG）**:\n",
    "    * 結合向量資料庫的檢索能力與 LLM 的生成能力，讓模型可以根據外部知識回答問題。\n",
    "4.  **工具呼叫（Function Calling/Tool Calling）**:\n",
    "    * 學習如何讓 LLM 呼叫外部工具或函式（例如我們建立的電影資料庫查詢工具）。\n",
    "    * 了解如何定義工具的結構描述（schema），以及處理模型的工具呼叫請求。\n",
    "5.  **結構化輸出（Structured Outputs）**:\n",
    "    * 學習如何讓 LLM 以特定的 JSON 格式輸出結果，確保輸出的可預測性和一致性。\n",
    "\n",
    "我們將會使用電影資料集作為範例，一步一步地完成這些概念的實作。準備好了嗎？開始囉！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/dachenlian/genai4humanities-wk14.git wk14\n",
    "!rm wk14/week14.ipynb\n",
    "!mv wk14/* .\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!uv pip install --system -r pyproject.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013138c",
   "metadata": {},
   "source": [
    "# 匯入（Imports）\n",
    "\n",
    "首先，我們需要匯入所有必要的 Python 套件。\n",
    "`autoreload` 可以讓我們在修改外部 Python 檔案後，不用重新啟動 Jupyter核心就能自動載入更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from enum import StrEnum\n",
    "from typing import Annotated  # 用於更精確的型別提示\n",
    "\n",
    "import lancedb  # 向量資料庫\n",
    "import pandas as pd  # 資料處理\n",
    "import tiktoken  # OpenAI 的 token 計算工具\n",
    "import torch  # PyTorch，用於張量運算\n",
    "import torch.nn.functional as F  # PyTorch 的函式庫，用於計算餘弦相似度等\n",
    "from datasets import load_dataset, load_from_disk  # Hugging Face Datasets 套件\n",
    "from dotenv import load_dotenv  # 讀取環境變數\n",
    "from huggingface_hub import AsyncInferenceClient  # Hugging Face 推論 API 客戶端\n",
    "from huggingface_hub.inference._generated.types import ChatCompletionOutputToolCall\n",
    "from loguru import logger  # 更方便的日誌記錄\n",
    "from pydantic import BaseModel, Field  # 資料驗證與設定管理\n",
    "from openai import OpenAI, AsyncOpenAI  # OpenAI API 客戶端\n",
    "from openai.types.chat.chat_completion_message_tool_call import (\n",
    "    ChatCompletionMessageToolCall,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer  # 句子嵌入模型\n",
    "from tenacity import (  # 用於重試機制\n",
    "    RetryCallState,\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "from utils import create_tool_schema_for_function  # 自訂的工具函式\n",
    "from tool_types import ToolCallResult  # 自訂的型別\n",
    "\n",
    "load_dotenv()  # 載入 .env 檔案中的環境變數\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata  # type: ignore # 嘗試從 Google Colab 讀取秘密金鑰\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "\n",
    "load_dotenv(override=True)  # 再次載入，確保 .env 的設定會覆寫已存在的環境變數\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", 0\n",
    ")  # 設定 pandas DataFrame 顯示欄位的最大寬度（0 代表不限制）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff471f3",
   "metadata": {},
   "source": [
    "# 準備資料集（Preparing dataset）\n",
    "\n",
    "我們將使用 [TMDB 5000 Movies](https://huggingface.co/datasets/AiresPucrs/tmdb-5000-movies) 資料集。\n",
    "這個資料集包含了約 5000 部電影的資訊，例如：概覽（overview）、類型（genres）、關鍵字（keywords）等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95891ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/AiresPucrs/tmdb-5000-movies\n",
    "ds = load_dataset(\"AiresPucrs/tmdb-5000-movies\", split=\"train\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332f7c6",
   "metadata": {},
   "source": [
    "## 資料預處理\n",
    "我們需要對資料集進行一些清理和轉換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e5281",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 移除 \"overview\" 欄位為空值的電影\n",
    "ds = ds.filter(lambda x: bool(x[\"overview\"]))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example: dict) -> dict:\n",
    "    \"\"\"\n",
    "    對單筆電影資料進行預處理。\n",
    "    - 將 JSON 字串解析為 Python 列表或字典。\n",
    "    - 轉換日期格式。\n",
    "    - 提取年份。\n",
    "    \"\"\"\n",
    "    example[\"genres\"] = [g[\"name\"] for g in json.loads(example[\"genres\"])]\n",
    "    example[\"keywords\"] = [k[\"name\"] for k in json.loads(example[\"keywords\"])]\n",
    "    example[\"release_date\"] = datetime.datetime.strptime(\n",
    "        d if (d := example[\"release_date\"]) else \"1970-01-01\", \"%Y-%m-%d\"\n",
    "    ).date()\n",
    "    example[\"release_year\"] = example[\"release_date\"].year\n",
    "    example[\"spoken_languages\"] = [\n",
    "        sl[\"name\"] for sl in json.loads(example[\"spoken_languages\"])\n",
    "    ]\n",
    "    example[\"cast\"] = [\n",
    "        {\n",
    "            \"name\": c[\"name\"],\n",
    "            \"character\": c[\"character\"],\n",
    "        }\n",
    "        for c in json.loads(example[\"cast\"])\n",
    "    ]\n",
    "    # 以下是被註解掉的欄位，暫不處理\n",
    "    # example[\"production_companies\"] = [\n",
    "    #     pc[\"name\"] for pc in json.loads(example[\"production_companies\"])\n",
    "    # ]\n",
    "    # example[\"production_countries\"] = [\n",
    "    #     pc[\"name\"] for pc in json.loads(example[\"production_countries\"])\n",
    "    # ]\n",
    "    # example[\"crew\"] = [\n",
    "    #     {\n",
    "    #         \"name\": c[\"name\"],\n",
    "    #         \"job\": c[\"job\"],\n",
    "    #     }\n",
    "    #     for c in json.loads(example[\"crew\"])\n",
    "    # ]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 .map() 方法對整個資料集進行預處理\n",
    "# remove_columns 會移除指定的原始欄位\n",
    "# num_proc 設定了並行處理的程序數量，可以加速處理\n",
    "ds = ds.map(\n",
    "    preprocess,\n",
    "    remove_columns=[\n",
    "        \"id\",  # 電影ID，通常不需要作為特徵\n",
    "        \"homepage\",  # 電影主頁連結\n",
    "        \"production_companies\",  # 製片公司\n",
    "        \"production_countries\",  # 製片國家\n",
    "        \"status\",  # 發行狀態\n",
    "        \"tagline\",  # 電影標語\n",
    "        \"vote_count\",  # 投票數量\n",
    "        \"vote_average\",  # 平均評分\n",
    "        \"crew\",  # 工作人員\n",
    "        \"original_title\",  # 原始標題 (稍後會用 'title'，若要保留原始標題可取消註解)\n",
    "    ],\n",
    "    num_proc=4,\n",
    ")\n",
    "ds[0]  # 顯示第一筆處理後的資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10bf2ef",
   "metadata": {},
   "source": [
    "# 嵌入（Embeddings）\n",
    "\n",
    "嵌入是將文字轉換為數值向量的過程。這些向量可以捕捉文字的語義資訊，讓機器可以理解文字之間的關係。\n",
    "意思相近的文字，其向量在向量空間中的距離也會比較近。\n",
    "\n",
    "我們會比較兩種產生嵌入的方式：\n",
    "1.  **sentence-transformers**: 一個開源的 Python 套件，提供了許多預訓練好的模型，可以在本機端執行。\n",
    "2.  **OpenAI API**: OpenAI 提供的付費服務，可以透過 API 取得高品質的文字嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"I want to watch an exciting superhero movie\",  # 我想看一部刺激的超級英雄電影\n",
    "    \"我想看一部超級英雄電影\",  # 中文查詢\n",
    "]\n",
    "\n",
    "movies = [\n",
    "    \"A movie about a group of friends who go on a road trip\",  # 一部關於一群朋友公路旅行的電影\n",
    "    \"A romantic comedy about a couple who meet at a wedding\",  # 一部關於一對在婚禮上相遇的情侶的浪漫喜劇\n",
    "    \"An autobiography of George Washington, the first president of the United States\",  # 美國第一任總統喬治華盛頓的自傳\n",
    "    \"Spider-Man is fighting against the Green Goblin in another universe\",  # 蜘蛛人在另一個宇宙對抗綠惡魔\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f1c42",
   "metadata": {},
   "source": [
    "## sentence-transformers\n",
    "\n",
    "* [官方文件](https://sbert.net/)\n",
    "* 支援 `sentence-transformers` 的模型：https://huggingface.co/models?library=sentence-transformers\n",
    "* 用於 `sentence-similarity`（句子相似度）任務的模型：https://huggingface.co/models?pipeline_tag=sentence-similarity\n",
    "\n",
    "我們將使用 `paraphrase-multilingual-MiniLM-L12-v2` 模型，它支援多種語言，包含英文和中文。\n",
    "`device=\"cpu\"` 表示我們將在 CPU 上執行模型。如果有 GPU，可以改為 `\"cuda\"`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b78690",
   "metadata": {},
   "source": [
    "### 計算嵌入（Compute embeddings）\n",
    "\n",
    "使用 `embedder.encode()` 方法將文字轉換為嵌入向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = embedder.encode(queries)\n",
    "movie_embeddings = embedder.encode(movies)\n",
    "print(\n",
    "    query_embeddings.shape, movie_embeddings.shape\n",
    ")  # .shape 顯示向量的維度 (數量, 維度大小)\n",
    "print(f\"Query: {query_embeddings[0][:5]}\")  # 顯示第一個查詢向量的前5個維度值\n",
    "print(f\"Movie: {movie_embeddings[0][:5]}\")  # 顯示第一個電影描述向量的前5個維度值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b195ce",
   "metadata": {},
   "source": [
    "### 計算相似度並擷取前 K 個（Computing similarity + retrieving top k）\n",
    "\n",
    "我們可以使用 `embedder.similarity()` 方法來計算兩組嵌入之間的餘弦相似度。\n",
    "餘弦相似度的值介於 -1 和 1 之間，越接近 1 代表越相似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945142c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算查詢嵌入和電影嵌入之間的餘弦相似度\n",
    "similarities = embedder.similarity(query_embeddings, movie_embeddings)\n",
    "similarities  # 輸出一個矩陣，列代表電影，欄代表查詢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = \"\\033[33m\"  # ANSI escape code，讓文字顯示為黃色\n",
    "END = \"\\033[0m\"  # ANSI escape code，重設文字顏色\n",
    "# 輸出所有查詢與電影的相似度分數\n",
    "for idx_i, sentence1 in enumerate(queries):\n",
    "    print(sentence1)\n",
    "    for idx_j, sentence2 in enumerate(movies):\n",
    "        print(\n",
    "            f\" - {sentence2: <30}: {YELLOW}{similarities[idx_i][idx_j]:.4f}{END}\"\n",
    "        )  # :.4f 表示格式化為小數點後4位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa62eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.topk() 可以找到張量中最大或最小的 k 個元素及其索引\n",
    "# similarities[0] 是第一個查詢與所有電影的相似度\n",
    "torch.topk(similarities[0], k=4)  # k=4 表示找出最相似的4部電影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出每個查詢最相似的 k 部電影\n",
    "for idx_i, sentence1 in enumerate(queries):\n",
    "    print(sentence1)\n",
    "    # torch.topk().indices 會回傳前 k 個最相似電影的索引\n",
    "    for idx_j in torch.topk(similarities[idx_i], k=4).indices:\n",
    "        print(f\" - {movies[idx_j]: <30}: {YELLOW}{similarities[idx_i][idx_j]:.4f}{END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c72fe",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "[官方文件](https://platform.openai.com/docs/guides/embeddings?lang=python)\n",
    "\n",
    "使用 OpenAI 的嵌入模型通常可以得到更好的效果，但需要 API 金鑰且有費用。\n",
    "\n",
    "我們將使用 `text-embedding-3-small` 模型，它在成本和效能之間取得了不錯的平衡。\n",
    "\n",
    "![](https://i.redd.it/lpf0u9nbj7w41.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key and userdata:\n",
    "    # 如果在 Google Colab 環境，嘗試從 userdata 取得 API 金鑰\n",
    "    api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY 環境變數未設定\")\n",
    "\n",
    "# 使用 AsyncOpenAI 進行非同步 API 呼叫，可以提高效率\n",
    "client = AsyncOpenAI(api_key=api_key, max_retries=5)  # max_retries 設定最大重試次數"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf1b53",
   "metadata": {},
   "source": [
    "### 計算嵌入（Compute embeddings）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 await 等待非同步函式的結果\n",
    "res = await client.embeddings.create(input=queries[0], model=\"text-embedding-3-small\")\n",
    "embedding = res.data[0].embedding\n",
    "print(len(embedding))  # 顯示嵌入向量的維度大小\n",
    "print(embedding[:5])  # 顯示向量的前5個維度值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.usage.total_tokens 顯示這次 API 呼叫消耗的 token 數量\n",
    "print(f\"Total tokens: {res.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d249a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 asyncio.gather 並行處理多個 API 呼叫，以節省時間\n",
    "_query_embeddings = await asyncio.gather(\n",
    "    *[\n",
    "        client.embeddings.create(input=query, model=\"text-embedding-3-small\")\n",
    "        for query in queries\n",
    "    ]\n",
    ")\n",
    "# 將 API 回傳的嵌入轉換為 PyTorch 張量 (Tensor)\n",
    "query_embeddings = torch.Tensor(\n",
    "    [embedding.data[0].embedding for embedding in _query_embeddings]\n",
    ")\n",
    "\n",
    "_movie_embeddings = await asyncio.gather(\n",
    "    *[\n",
    "        client.embeddings.create(input=movie, model=\"text-embedding-3-small\")\n",
    "        for movie in movies\n",
    "    ]\n",
    ")\n",
    "movie_embeddings = torch.Tensor(\n",
    "    [embedding.data[0].embedding for embedding in _movie_embeddings]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829db4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_embeddings 已經是 PyTorch 張量了，這裡再次轉換 torch.Tensor(movie_embeddings) 是多餘的\n",
    "# 但為了保持與 notebook 一致，暫不修改。\n",
    "torch.Tensor(movie_embeddings)  # 這裡的 movie_embeddings 已經是 torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0d3a4",
   "metadata": {},
   "source": [
    "### 計算相似度並擷取前 K 個（Computing similarity + retrieving top k）\n",
    "\n",
    "我們使用 `torch.nn.functional.cosine_similarity` (別名為 `F.cosine_similarity`) 來計算餘弦相似度。\n",
    "`unsqueeze()` 方法用於增加張量的維度，以符合 `cosine_similarity` 的輸入要求。\n",
    "`dim=2` 表示沿著第三個維度（索引為2）計算相似度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = F.cosine_similarity(\n",
    "    query_embeddings.unsqueeze(1),  # (num_queries, 1, embedding_dim)\n",
    "    movie_embeddings.unsqueeze(0),  # (1, num_movies, embedding_dim)\n",
    "    dim=2,  # 結果維度 (num_queries, num_movies)\n",
    ")\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4567c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = \"\\033[33m\"\n",
    "END = \"\\033[0m\"\n",
    "for idx_i, sentence1 in enumerate(queries):\n",
    "    print(sentence1)\n",
    "    for idx_j in torch.topk(similarities[idx_i], k=4).indices:\n",
    "        print(f\" - {movies[idx_j]: <30}: {YELLOW}{similarities[idx_i][idx_j]:.4f}{END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94acad8",
   "metadata": {},
   "source": [
    "### 計算 token 數量與價格（Calculate tokens and price）\n",
    "\n",
    "[OpenAI 價格](https://platform.openai.com/docs/pricing)\n",
    "\n",
    "使用 `tiktoken` 套件可以計算 OpenAI 模型處理文字時會消耗多少 token。\n",
    "不同的模型有不同的計價方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d186daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得 \"text-embedding-3-small\" 模型對應的編碼器\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0370e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = enc.encode(queries[0])  # 將文字編碼為 token ID 列表\n",
    "print(f\"Total tokens: {len(encoded)}\")\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edebe03",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 不同嵌入模型的每百萬 token 價格 (美元)\n",
    "model_to_price = {\n",
    "    \"text-embedding-3-small\": 0.02,  # 價格較低\n",
    "    \"text-embedding-3-large\": 0.13,  # 價格較高，但通常效果更好\n",
    "}\n",
    "\n",
    "\n",
    "def get_token_count_and_price(\n",
    "    texts: list[str], model: str = \"text-embedding-3-small\"\n",
    ") -> tuple[int, float]:\n",
    "    \"\"\"\n",
    "    計算一批文字的總 token 數和預估價格。\n",
    "    \"\"\"\n",
    "    if model not in model_to_price:\n",
    "        raise ValueError(f\"不支援的模型 {model}\")\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    # encode_batch 可以一次處理多筆文字，效率較高\n",
    "    token_count = sum(len(e) for e in enc.encode_batch(texts))\n",
    "    price_per_1m_tokens = model_to_price[model]\n",
    "    price = (token_count / 1_000_000) * price_per_1m_tokens\n",
    "    return token_count, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a256c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 估算 movies 列表重複10次的 token 數和價格\n",
    "get_token_count_and_price(movies * 10, model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0884fd4",
   "metadata": {},
   "source": [
    "### 處理速率限制（Handling rate limits）\n",
    "\n",
    "當短時間內大量呼叫 API 時，可能會觸發速率限制 (rate limits)。\n",
    "`tenacity` 套件可以幫助我們實作重試機制，例如指數退避 (exponential backoff)。\n",
    "指數退避是指每次重試的等待時間會逐漸增加，避免對 API 造成過大負載。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e30c8e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def log_backoff_attempt(retry_state: RetryCallState) -> None:\n",
    "    \"\"\"\n",
    "    在每次重試前記錄日誌。\n",
    "    \"\"\"\n",
    "    attempt_num = retry_state.attempt_number  # 第幾次重試\n",
    "    exception = (\n",
    "        retry_state.outcome.exception() if retry_state.outcome else \"N/A\"\n",
    "    )  # 觸發重試的例外\n",
    "    wait_time = (\n",
    "        retry_state.next_action.sleep if retry_state.next_action else 0.0\n",
    "    )  # 下次重試前的等待時間\n",
    "    func_name = (\n",
    "        retry_state.fn.__name__ if retry_state.fn else \"N/A\"\n",
    "    )  # 正在重試的函式名稱\n",
    "\n",
    "    logger.info(\n",
    "        f\"函式 '{func_name}' 退避中： \"\n",
    "        f\"第 {attempt_num} 次嘗試因 '{exception.__class__.__name__}: {exception}' 失敗。 \"\n",
    "        f\"下次嘗試前等待 {wait_time:.2f} 秒。\"\n",
    "    )\n",
    "\n",
    "\n",
    "@retry(\n",
    "    wait=wait_random_exponential(\n",
    "        min=1, max=60\n",
    "    ),  # 等待時間為指數增加，最小1秒，最大60秒，並加入隨機性\n",
    "    stop=stop_after_attempt(6),  # 最多重試6次\n",
    "    before_sleep=log_backoff_attempt,  # 每次重試前呼叫 log_backoff_attempt\n",
    ")\n",
    "async def embedding_with_backoff(**kwargs):\n",
    "    \"\"\"\n",
    "    帶有指數退避重試機制的嵌入函式。\n",
    "    \"\"\"\n",
    "    return await client.embeddings.create(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581c60b",
   "metadata": {},
   "source": [
    "# 設定向量資料庫（Setting up a vector database）\n",
    "\n",
    "[LanceDB 文件](https://lancedb.github.io/lancedb/basic/)\n",
    "\n",
    "向量資料庫專門用於儲存和檢索向量嵌入。\n",
    "LanceDB 是一個開源的、無伺服器的向量資料庫，很容易在本機端使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9098a",
   "metadata": {},
   "source": [
    "## 建立 LanceDB 表格（Creating a LanceDB table）\n",
    "\n",
    "我們將使用電影的 \"overview\"（概覽）欄位來產生嵌入並存入資料庫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds 是我們之前預處理好的 Hugging Face Dataset 物件\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "overviews = ds[\"overview\"]  # 取出所有電影的概覽文字\n",
    "print(len(overviews))\n",
    "overviews[:5]  # 顯示前5筆概覽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.features  # 顯示資料集的欄位資訊和型別"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a25952",
   "metadata": {},
   "source": [
    "## 使用 sentence-transformers 產生嵌入\n",
    "\n",
    "我們將使用先前載入的 `sentence-transformers` 模型來為所有電影概覽產生嵌入。\n",
    "這一步在本機執行，不需要 API 金鑰。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e49ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為所有電影概覽產生嵌入\n",
    "# 這一行程式碼執行時間可能會比較久，取決於資料量和硬體效能\n",
    "overview_embeddings = embedder.encode(overviews)\n",
    "overview_embeddings[0][:5]  # 顯示第一個概覽嵌入的前5個維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_embeddings.shape  # (電影數量, 嵌入維度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e674d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將產生的嵌入向量作為新的一欄 \"vector\" 加入到我們的資料集中\n",
    "# .tolist() 是因為 Hugging Face Datasets 在新增欄位時，若資料是 numpy array，通常需要轉成 list\n",
    "ds = ds.add_column(name=\"vector\", column=overview_embeddings.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29912e95",
   "metadata": {},
   "source": [
    "### 將結果儲存到磁碟（Save results to disk）\n",
    "\n",
    "處理完的資料集可以儲存起來，方便之後載入使用，避免重複運算。\n",
    "Hugging Face Datasets 提供了 `save_to_disk` 方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c63aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk(\"./data/dataset_processed\")  # 將資料集儲存到指定路徑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f5419",
   "metadata": {},
   "source": [
    "#### 將結果儲存到 Google Drive（Save results to Google Drive）\n",
    "\n",
    "如果你在 Google Colab 環境中執行，可以將資料儲存到 Google Drive，方便持久化儲存。\n",
    "這段程式碼只有在 Colab 環境中才需要執行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\") # 掛載 Google Drive\n",
    "# !mkdir -p \"/content/drive/My Drive/genai4h-wk14\" # 在 Google Drive 建立資料夾\n",
    "# !cp -r \"./data/dataset_processed\" \"/content/drive/My Drive/genai4h-wk14/\" # 將處理好的資料複製到 Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d52a7",
   "metadata": {},
   "source": [
    "### 從磁碟載入結果（Load results from disk）\n",
    "\n",
    "使用 `load_from_disk` 可以快速載入之前儲存的資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a73453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\n",
    "    \"./data/dataset_processed\"\n",
    ")  # 從磁碟載入處理好的資料集 (注意路徑與儲存時一致)\n",
    "ds[0]  # 檢查載入的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 Hugging Face Dataset 轉換為 pandas DataFrame，方便後續操作\n",
    "df = ds.to_pandas()\n",
    "df.iloc[0]  # 顯示 DataFrame 的第一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00208c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連接到 LanceDB 資料庫\n",
    "# 如果 \"./data/lance_db\" 路徑不存在，LanceDB 會自動建立它\n",
    "db = lancedb.connect(\"./data/lance_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef520b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一個名為 \"movies\" 的表格\n",
    "# data=df 表示使用我們的 DataFrame 作為資料來源\n",
    "# mode=\"overwrite\" 表示如果 \"movies\" 表格已存在，則覆寫它\n",
    "tbl = db.create_table(\"movies\", data=df, mode=\"overwrite\")\n",
    "# 對 \"overview\" 欄位建立全文檢索 (FTS) 索引，可以加速關鍵字搜尋\n",
    "# 注意：這裡的 FTS 索引是針對 \"overview\" 這個文字欄位，而不是向量欄位\n",
    "tbl.create_fts_index(\"overview\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86589b85",
   "metadata": {},
   "source": [
    "### 使用 OpenAI 產生嵌入（OpenAI）\n",
    "\n",
    "[嵌入太慢？(Slow embeddings?)](https://community.openai.com/t/embeddings-api-extremely-slow/1135044)\n",
    "\n",
    "如果選擇使用 OpenAI API 來產生所有電影概覽的嵌入，請注意：\n",
    "1.  **費用**：資料量大時，費用可能會比較高。\n",
    "2.  **時間**：即使使用 `asyncio.gather` 和重試機制，處理大量文字也可能需要一些時間。\n",
    "\n",
    "以下程式碼是使用 OpenAI 產生嵌入的範例。如果先前已使用 `sentence-transformers` 產生並儲存了嵌入，可以跳過這部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5aea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "overviews = ds[\"overview\"]  # 再次取得電影概覽\n",
    "# 計算使用 OpenAI \"text-embedding-3-small\" 模型處理所有概覽所需的 token 數和預估價格\n",
    "get_token_count_and_price(overviews, model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 註解掉以下區塊，因為我們已經使用 sentence-transformers 產生嵌入\n",
    "# # 如果要改用 OpenAI，請取消註解並執行\n",
    "#\n",
    "# # 使用帶有重試機制的 embedding_with_backoff 函式，為每個概覽文字產生嵌入\n",
    "# _overview_embeddings = await asyncio.gather(\n",
    "#     *[\n",
    "#         embedding_with_backoff(input=overview, model=\"text-embedding-3-small\")\n",
    "#         # client.embeddings.create(input=overview, model=\"text-embedding-3-small\") # 不帶重試的版本\n",
    "#         for overview in overviews\n",
    "#     ]\n",
    "# )\n",
    "# overview_embeddings = [\n",
    "#     embedding.data[0].embedding for embedding in _overview_embeddings\n",
    "# ]\n",
    "# overview_embeddings[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 註解掉以下區塊，因為我們已經使用 sentence-transformers 產生嵌入\n",
    "# df = ds.to_pandas() # 如果前面沒有轉 DataFrame，這裡需要轉換\n",
    "# df[\"vector\"] = overview_embeddings # 將 OpenAI 產生的嵌入存到 DataFrame 的 \"vector\" 欄\n",
    "# # 之後可以像 sentence-transformers 的情況一樣，用這個 df 建立 LanceDB 表格"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569f3ff",
   "metadata": {},
   "source": [
    "# 向量搜尋（Vector search）\n",
    "\n",
    "* [向量搜尋 (Vector search)](https://lancedb.github.io/lancedb/search/)\n",
    "* [混合搜尋 (Hybrid search)](https://lancedb.github.io/lancedb/hybrid_search/hybrid_search/) (結合向量搜尋和關鍵字搜尋)\n",
    "* [關鍵字搜尋 (Keyword search)](https://lancedb.github.io/lancedb/fts/) (需要先對文字欄位建立 FTS 索引)\n",
    "\n",
    "混合搜尋和關鍵字搜尋對於跨語言搜尋的效果可能不如純向量搜尋（如果使用的嵌入模型支援多語言）。\n",
    "向量搜尋的核心是計算查詢向量與資料庫中所有向量的相似度，並找出最相似的結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1243e1c",
   "metadata": {},
   "source": [
    "## 載入嵌入模型（Load embedding model）\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "⚠️ **警告**：必須使用與建立資料庫時相同的嵌入模型來產生查詢向量。否則，向量空間不一致，搜尋結果會沒有意義。\n",
    "</div>\n",
    "\n",
    "因為我們之前是用 `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` 建立的 LanceDB 表格，\n",
    "所以這裡也要載入同一個模型來產生查詢的嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a937630",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連接到先前建立的 LanceDB 資料庫並開啟 \"movies\" 表格\n",
    "db = lancedb.connect(\"./data/lance_db/\")\n",
    "tbl = db.open_table(\"movies\")\n",
    "# 再次確認 \"overview\" 欄位有 FTS 索引 (如果之前已建立，replace=True 會覆寫)\n",
    "# 這一步驟是為了確保 FTS 索引存在，如果只是做向量搜尋，可以不執行。\n",
    "tbl.create_fts_index(\"overview\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb214e",
   "metadata": {},
   "source": [
    "## 嵌入查詢（Embed the query）\n",
    "\n",
    "將使用者的查詢文字轉換為嵌入向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9199a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_en = \"I want to watch a romantic comedy\"  # 英文查詢：我想看一部浪漫喜劇\n",
    "q_zh = \"我想看一部浪漫喜劇\"  # 中文查詢\n",
    "\n",
    "q_en_embedding = embedder.encode(q_en)\n",
    "q_zh_embedding = embedder.encode(q_zh)\n",
    "print(len(q_en_embedding), len(q_zh_embedding))  # 顯示嵌入向量的維度\n",
    "print(q_en_embedding[:5], q_zh_embedding[:5])  # 顯示前5個維度值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81b838",
   "metadata": {},
   "source": [
    "## 查詢資料庫（Querying the database）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf600c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生一個隨機向量，用於測試\n",
    "random_vector = torch.randn(10).numpy()  # 產生一個10維的隨機向量\n",
    "random_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c5018",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "⚠️ **警告**：以下程式碼會失敗，因為隨機向量的維度 (10) 與資料庫中儲存的嵌入維度 (384，由 `paraphrase-multilingual-MiniLM-L12-v2` 產生) 不符。👇\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.search(random_vector).limit(5).to_pandas()  # 這行會報錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用英文查詢向量進行搜尋\n",
    "# .select([\"overview\"]) 指定只回傳 \"overview\" 欄位\n",
    "# .limit(5) 指定回傳最相似的5筆結果\n",
    "# .to_pandas() 將結果轉換為 DataFrame\n",
    "tbl.search(q_en_embedding).select([\"overview\"]).limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030739f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用中文查詢向量進行搜尋\n",
    "tbl.search(q_zh_embedding).select([\"overview\", \"title\"]).limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d6750",
   "metadata": {},
   "source": [
    "# 工具呼叫（Function calling）\n",
    "\n",
    "工具呼叫（或稱函式呼叫）讓大型語言模型（LLM）可以與外部工具或 API 互動。\n",
    "LLM 本身不具備執行程式碼或查詢資料庫的能力，但透過工具呼叫，我們可以賦予它這些能力。\n",
    "\n",
    "我們將以 RAG（檢索增強生成）作為範例，展示 LLM 如何呼叫我們定義的電影資料庫查詢工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d7210",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 再次確認嵌入模型和資料庫已載入\n",
    "embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "db = lancedb.connect(\"./data/lance_db\")\n",
    "tbl = db.open_table(\"movies\")  # 開啟 \"movies\" 表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_movie_db(\n",
    "    text: str,\n",
    "    limit: int = 10,\n",
    ") -> ToolCallResult:  # ToolCallResult 是我們自訂的回傳型別\n",
    "    \"\"\"\n",
    "    查詢 LanceDB 電影資料庫，找出與輸入文字概覽相似的電影。\n",
    "\n",
    "    Args:\n",
    "        text (str): 用於查詢資料庫的輸入文字。\n",
    "        limit (int, optional): 回傳結果的數量，預設為 10。\n",
    "\n",
    "    Returns:\n",
    "        ToolCallResult: 包含給 LLM 使用的 JSON 字串和給 UI 顯示的 DataFrame。\n",
    "    \"\"\"\n",
    "    q_emb = embedder.encode(text)  # 將查詢文字轉換為嵌入\n",
    "    df = (\n",
    "        tbl.search(q_emb)\n",
    "        .limit(limit)\n",
    "        .to_pandas()\n",
    "        .drop(\n",
    "            columns=[\"vector\", \"_distance\"]\n",
    "        )  # 移除 \"vector\" 和 \"_distance\" 欄位，簡化輸出\n",
    "    )\n",
    "    return {\n",
    "        \"llm_consumable\": df.to_json(\n",
    "            lines=True, orient=\"records\"\n",
    "        ),  # 轉換為 JSON Lines 格式，方便 LLM 解析\n",
    "        \"ui_displayable\": df,  # DataFrame 可以直接在 Jupyter Notebook 中顯示\n",
    "        \"return_type\": \"dataframe\",  # 標註回傳型別\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試 query_movie_db 函式\n",
    "res = query_movie_db(\"air bud\")  # 查詢關於電影 \"air bud\" (一隻會打籃球的狗)\n",
    "print(res[\"llm_consumable\"])  # 印出給 LLM 的 JSON 字串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f5de0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "res[\"ui_displayable\"].iloc[0]  # 顯示查詢結果 DataFrame 的第一筆資料"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbd8c3",
   "metadata": {},
   "source": [
    "## 建立 JSON 結構描述（Creating a JSON schema）\n",
    "\n",
    "為了讓 LLM 知道我們的工具有哪些參數、以及如何使用它們，我們需要提供一個 JSON 結構描述 (JSON Schema)。\n",
    "Pydantic BaseModel 可以方便地定義資料結構，並自動產生 JSON Schema。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10aab96",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 使用 Pydantic BaseModel 定義 query_movie_db 函式的參數結構\n",
    "class QueryMovieDB(BaseModel):\n",
    "    text: str = Field(\n",
    "        description=\"用來查詢電影概覽的文字 (Query overviews of movies)\",\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        default=10,  # 預設值\n",
    "        description=\"回傳結果的數量 (Number of results to return)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99735e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_tool_schema_for_function 是我們在 utils.py 中定義的輔助函式\n",
    "# 它可以根據函式本身和 Pydantic模型產生符合 LLM 工具呼叫格式的 JSON Schema\n",
    "schema = create_tool_schema_for_function(query_movie_db, QueryMovieDB)\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733bae8",
   "metadata": {},
   "source": [
    "## Hugging Face InferenceClient\n",
    "\n",
    "* [Hugging Face InferenceClient 工具呼叫文件](https://huggingface.co/docs/hugs/en/guides/function-calling)\n",
    "\n",
    "Hugging Face InferenceClient 可以讓我們方便地呼叫部署在 Hugging Face 或其他供應商（如 Fireworks AI）上的 LLM。\n",
    "有些模型支援工具呼叫功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.getenv(\"HF_TOKEN\")  # 從環境變數讀取 Hugging Face API Token\n",
    "if hf_token is None and userdata:\n",
    "    # 如果在 Google Colab 環境，嘗試從 userdata 取得 Hugging Face API Token\n",
    "    hf_token = userdata.get(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN 環境變數未設定\")\n",
    "\n",
    "# 初始化 AsyncInferenceClient\n",
    "# provider=\"fireworks-ai\" 表示我們將使用 Fireworks AI 提供的模型服務\n",
    "# 需要有 Fireworks AI 的帳號並設定好 HF_TOKEN (通常與 Fireworks AI 的 API Key 相同或相關)\n",
    "hf_client = AsyncInferenceClient(\n",
    "    provider=\"fireworks-ai\",  # 這裡指定使用 Fireworks AI 作為模型提供者\n",
    "    api_key=hf_token,  # Fireworks AI 的 API 金鑰\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafe23c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"不要對數值做假設。如果需要，請要求澄清。(Don't make assumptions about values. Ask for clarification if needed.)\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"我想看一部關於一位被迫重出江湖的退休刺客的電影。 /no_think (I'd like to watch a movie about a retired assassin who is forced back into the game. /no_think)\",\n",
    "        # \"/no_think\" 是一個提示詞技巧，有時可以讓模型更傾向於呼叫工具而不是直接回答\n",
    "    },\n",
    "]\n",
    "\n",
    "# 呼叫 LLM\n",
    "# model=\"Qwen/Qwen3-235B-A22B\" 是 Fireworks AI 上的一個模型，支援工具呼叫\n",
    "# tools=[schema] 提供了我們定義的 query_movie_db 工具的 JSON Schema\n",
    "# tool_choice=\"auto\" 允許模型自行決定是否以及呼叫哪個工具\n",
    "# 其他選項: \"required\": 強制模型呼叫一個或多個工具; \"none\": 禁止模型呼叫工具\n",
    "response = await hf_client.chat_completion(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",  # 這裡需要填寫 Fireworks AI 上支援工具呼叫的模型 ID\n",
    "    messages=messages,\n",
    "    tools=[schema],  # 提供工具的 schema\n",
    "    tool_choice=\"auto\",\n",
    ")  # type: ignore # 忽略型別檢查的警告\n",
    "print(response.choices[0].message.tool_calls)  # 印出模型決定呼叫的工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e262abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的模型回覆訊息\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4435df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型回覆的工具呼叫中的函式部分 (字串格式)\n",
    "str(response.choices[0].message.tool_calls[0].function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2dcd9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 解析後的工具呼叫函式物件\n",
    "func = response.choices[0].message.tool_calls[0].function\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905abde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.tool_calls[0].id)  # 工具呼叫的唯一 ID\n",
    "print(func.name)  # 被呼叫的函式名稱 (應該是 \"query_movie_db\")\n",
    "print(json.loads(func.arguments))  # 被呼叫的函式參數 (JSON 字串轉為 Python 字典)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839e597",
   "metadata": {},
   "source": [
    "### 串流模式有點麻煩 (Streaming kind of a hassle)\n",
    "\n",
    "Hugging Face InferenceClient 也支援串流模式 (stream=True)，可以逐步接收模型的輸出。\n",
    "但在工具呼叫的場景下，解析串流的工具呼叫資訊會比較複雜，需要手動組合訊息片段。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ed111",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await hf_client.chat_completion(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",\n",
    "    messages=messages,\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,  # 開啟串流模式\n",
    ")  # type: ignore\n",
    "chunks = []\n",
    "async for chunk in response:\n",
    "    chunks.append(chunk)\n",
    "    print(chunk)  # 逐塊印出收到的訊息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"你是一個樂於助人的助理。只在你確定需要時才查詢資料庫。(You are a helpful assistant. Only query the database if you are sure it is needed.)\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"我想看一部關於超級英雄的電影。 /no_think (I want to watch a movie about superheroes. /no_think)\",\n",
    "    },\n",
    "]\n",
    "# hf_client.chat.completions.create 是另一個呼叫聊天模型的介面，用法類似\n",
    "response = await hf_client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",\n",
    "    messages=messages,\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")  # type: ignore\n",
    "chunks = []\n",
    "async for chunk in response:\n",
    "    chunks.append(chunk)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2c7b0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## OpenAI\n",
    "\n",
    "* [OpenAI 工具呼叫文件](https://platform.openai.com/docs/guides/function-calling?api-mode=chat)\n",
    "* [慷慨的免費額度 (Generous free tier)](https://platform.openai.com/docs/models/gpt-4.1-nano)\n",
    "\n",
    "OpenAI 的 API 也支援工具呼叫，並且整合得相當好。\n",
    "`gpt-4.1-nano` 是一個較新的、可能會有免費額度的模型 (請查閱 OpenAI 最新政策)。\n",
    "\n",
    "![](https://i.ibb.co/JwZtC9px/Screenshot-2025-05-20-235653.png \"GPT-4.1-nano\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9329d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if oai_api_key is None and userdata:\n",
    "    # 如果在 Google Colab 環境，嘗試從 userdata 取得 OpenAI API 金鑰\n",
    "    oai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "if not oai_api_key:\n",
    "    # 如果沒有找到 OpenAI API 金鑰，則拋出錯誤\n",
    "    raise ValueError(\"OPENAI_API_KEY 環境變數未設定\")\n",
    "oai_client = AsyncOpenAI(api_key=oai_api_key)  # 初始化 OpenAI 非同步客戶端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f75378",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"不要對數值做假設。如果需要，請要求澄清。\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"我想看一部關於一位被迫重出江湖的退休刺客的電影。\",\n",
    "    },\n",
    "]\n",
    "\n",
    "response = await oai_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",  # 或其他支援工具呼叫的 OpenAI 模型\n",
    "    messages=messages,\n",
    "    tools=[schema],  # 同樣提供工具的 JSON Schema\n",
    "    tool_choice=\"auto\",  # 讓模型自動決定\n",
    ")\n",
    "print(response.choices[0].message.tool_calls)  # 印出模型回傳的工具呼叫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84963559",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# OpenAI 回傳的工具呼叫物件\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一個可用的函式字典，方便根據名稱呼叫\n",
    "AVAILABLE_FUNCTIONS = {\n",
    "    \"query_movie_db\": query_movie_db,  # 將函式名稱對應到實際的函式物件\n",
    "}\n",
    "\n",
    "\n",
    "def call_function(name: str, args: dict) -> ToolCallResult:\n",
    "    \"\"\"\n",
    "    根據函式名稱和參數呼叫對應的函式。\n",
    "    包含基本的錯誤處理。\n",
    "    \"\"\"\n",
    "    func = AVAILABLE_FUNCTIONS.get(name)\n",
    "    if not func:\n",
    "        # raise ValueError(f\"未知的函式： {name}\")\n",
    "        error_msg = f\"錯誤：找不到工具 '{name}'。\"\n",
    "        print(error_msg)\n",
    "        return {\n",
    "            \"llm_consumable\": error_msg,\n",
    "            \"ui_displayable\": error_msg,\n",
    "            \"return_type\": \"error_message\",\n",
    "        }\n",
    "    try:\n",
    "        # 使用 **args 將字典解包為函式的關鍵字參數\n",
    "        return func(**args)\n",
    "    except TypeError as e:  # 捕捉參數不符等 TypeError\n",
    "        error_msg = f\"錯誤：呼叫工具 '{name}' 時參數不符，參數：{args}。詳細資訊：{e}\"\n",
    "        print(error_msg)\n",
    "        return {\n",
    "            \"llm_consumable\": error_msg,\n",
    "            \"ui_displayable\": error_msg,\n",
    "            \"return_type\": \"error_message\",\n",
    "        }\n",
    "    except Exception as e:  # 捕捉工具執行期間的其他錯誤\n",
    "        error_msg = f\"錯誤：執行工具 '{name}' (參數：{args}) 時發生錯誤。詳細資訊：{e}\"\n",
    "        print(error_msg)\n",
    "        return {\n",
    "            \"llm_consumable\": error_msg,\n",
    "            \"ui_displayable\": error_msg,\n",
    "            \"return_type\": \"error_message\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49994e8",
   "metadata": {},
   "source": [
    "## 檢查 LLM 回應中的工具呼叫（Check for function calls in LLM response）\n",
    "\n",
    "當 LLM 決定呼叫工具時，它的回應會包含 `tool_calls` 欄位。\n",
    "我們需要：\n",
    "1.  檢查 `tool_calls` 是否存在。\n",
    "2.  如果存在，解析工具呼叫的資訊（名稱、參數）。\n",
    "3.  執行對應的工具函式。\n",
    "4.  將工具函式的執行結果回傳給 LLM，讓它可以根據結果繼續生成回應。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncInferenceClient(provider=\"fireworks-ai\", api_key=hf_token)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Don't make assumptions about values. Ask for clarification if needed.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'd like to watch a movie about a retired assassin who is forced back into the game. /no_think\",  # 不要讓模型思考\n",
    "    },\n",
    "]\n",
    "\n",
    "# 呼叫 LLM 的 chat_completion API\n",
    "# model: 指定要使用的 LLM 模型名稱\n",
    "# messages: 包含完整對話歷史的訊息列表\n",
    "# tools: 提供給 LLM 的可用工具的結構描述列表\n",
    "# tool_choice: \"auto\" 表示讓 LLM 自行決定是否以及呼叫哪個工具\n",
    "# stream=True 被註解掉了，表示目前不使用串流模式。串流模式下處理工具呼叫會比較複雜。\n",
    "response = await client.chat_completion(  # type: ignore # 忽略型別檢查器的警告\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",  # 使用 Fireworks AI 上的 Qwen 模型\n",
    "    messages=messages,\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\",\n",
    "    # stream=True,  # streaming is a lot of work to handle tool calls and regular messages\n",
    ")  # type: ignore\n",
    "\n",
    "\n",
    "# 從 LLM 的回應中取得工具呼叫的資訊\n",
    "# response.choices[0].message 是 LLM 的主要回覆內容\n",
    "# .tool_calls 可能包含一個或多個模型決定呼叫的工具\n",
    "tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "# 檢查 LLM 是否真的要求呼叫工具\n",
    "if tool_calls:\n",
    "    # 假設只處理第一個工具呼叫 (如果模型可能一次呼叫多個，這裡需要迴圈處理)\n",
    "    tc: ChatCompletionOutputToolCall = tool_calls[0]\n",
    "    # 記錄被呼叫的工具資訊\n",
    "\n",
    "    # 取得工具呼叫的唯一 ID (call_id)，稍後將工具執行結果傳回給 LLM 時會用到\n",
    "    call_id = tc.id\n",
    "    # 取得被呼叫的函式名稱\n",
    "    func_name = tc.function.name\n",
    "    # 解析 LLM 提供的函式參數 (從 JSON 字串轉換為 Python 字典)\n",
    "    func_args = json.loads(tc.function.arguments)\n",
    "\n",
    "    # 實際執行工具函式\n",
    "    # call_function 是我們自己定義的函式，它會根據 func_name 和 func_args 執行對應的工具\n",
    "    tool_result = call_function(func_name, func_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea414e",
   "metadata": {},
   "source": [
    "# 結構化輸出（Structured outputs）\n",
    "\n",
    "有時候，我們希望 LLM 的輸出遵循特定的格式，例如 JSON。\n",
    "結構化輸出可以讓我們更容易地解析和使用 LLM 的回應。\n",
    "\n",
    "我們可以使用 Pydantic BaseModel 來定義期望的輸出結構。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StrEnum 是 Python 3.11+ 的功能，繼承自 str 和 Enum，讓列舉成員本身就是字串\n",
    "class Polarity(StrEnum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEGATIVE = \"negative\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "\n",
    "\n",
    "class SentimentAnalysisOutput(BaseModel):\n",
    "    # Annotated 可以為欄位加上額外的描述或限制\n",
    "    polarity: Annotated[Polarity, \"文字的情感極性 (The sentiment polarity of the text)\"]\n",
    "    confidence: Annotated[\n",
    "        float,\n",
    "        Field(\n",
    "            description=\"情感極性的信賴分數，介於 0 和 1 之間 (The confidence score of the sentiment polarity between 0 and 1)\",\n",
    "            ge=0.0,  # ge: greater than or equal to (大於等於)\n",
    "            le=1.0,  # le: less than or equal to (小於等於)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "# SentimentAnalysisOutput.model_json_schema() 可以產生此 Pydantic 模型的 JSON Schema\n",
    "print(json.dumps(SentimentAnalysisOutput.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 這裡會拋出 Pydantic 的 ValidationError，因為 confidence=1.1 超出了定義的範圍 (le=1.0)\n",
    "try:\n",
    "    SentimentAnalysisOutput(polarity=\"positive\", confidence=1.1)\n",
    "except Exception as e:\n",
    "    print(e)  # 印出錯誤訊息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab182c7b",
   "metadata": {},
   "source": [
    "## 準備提示（Prepare prompt）\n",
    "\n",
    "提示中需要清楚地告知 LLM 我們期望的 JSON 格式，包含欄位名稱和值的範例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\\\n",
    "請分析以下文字的情感（正面、負面或中性），並以 JSON 格式回傳結果。\n",
    "JSON 應包含以下欄位：\n",
    "- polarity: 文字的情感極性（positive、negative 或 neutral）\n",
    "- confidence: 情感極性的信賴分數，介於 0（不確定）和 1（非常確定）之間\n",
    "JSON 格式應如下：\n",
    "{{\n",
    "    \"polarity\": \"positive\",\n",
    "    \"confidence\": 0.95\n",
    "}}\n",
    "文字： {text}\n",
    "\"\"\"\n",
    "\n",
    "text_to_analyze = \"香菜加在任何東西上都超讚的！(Cilantro is amazing on everything!)\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": base_prompt.format(text=text_to_analyze),\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27bda4",
   "metadata": {},
   "source": [
    "## Hugging Face InferenceClient\n",
    "\n",
    "對於 Hugging Face InferenceClient，我們需要在 `chat_completion` 的 `response_format` 參數中提供期望的 JSON Schema。\n",
    "`response_format={\"type\": \"json_object\", \"value\": SCHEMA}`\n",
    "某些模型（例如較新的 Qwen 模型）支援這個功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await hf_client.chat_completion(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",  # 確認此模型支援 JSON 模式和 schema 指定\n",
    "    messages=messages,\n",
    "    response_format={\n",
    "        \"type\": \"json_object\",  # 指定回傳型別為 JSON 物件\n",
    "        \"value\": SentimentAnalysisOutput.model_json_schema(),  # 提供 Pydantic 模型的 JSON Schema\n",
    "    },\n",
    ")  # type: ignore\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51fbcae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# LLM 回傳的原始 JSON 字串內容\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8854f6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 將 JSON 字串解析為 Python 字典\n",
    "response_dict = json.loads(response.choices[0].message.content)\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58244de8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 使用 Pydantic 模型驗證並轉換字典\n",
    "# 如果 response_dict 的結構符合 SentimentAnalysisOutput，則會成功轉換\n",
    "# 否則會拋出 ValidationError\n",
    "sentiment_result = SentimentAnalysisOutput(**response_dict)\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405fcc1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Pydantic 模型提供了 model_validate_json 方法，可以直接從 JSON 字串驗證並轉換\n",
    "sentiment_result = SentimentAnalysisOutput.model_validate_json(\n",
    "    response.choices[0].message.content\n",
    ")\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e948ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 存取 Pydantic 物件的屬性\n",
    "str(sentiment_result.polarity)  # .polarity 是 Polarity 列舉型別，str() 可以取得其字串值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd4739",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "[OpenAI 結構化輸出文件](https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat)\n",
    "\n",
    "OpenAI 的 Python SDK 提供了更方便的方式來處理結構化輸出。\n",
    "可以直接將 Pydantic 模型傳遞給 `response_format` 參數 (使用 `openai.beta.chat.completions.parse` 時)。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "⚠️ **注意**：我們使用 `client.beta.chat.completions.parse` 而不是 `client.chat.completions.create`。\n",
    "`parse` 方法會自動處理 JSON 解析並驗證 Pydantic 模型。\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 client.beta.chat.completions.parse\n",
    "# 將 Pydantic 模型 SentimentAnalysisOutput 直接傳給 response_format\n",
    "response = await oai_client.beta.chat.completions.parse(\n",
    "    messages=messages,\n",
    "    model=\"gpt-4.1-nano\",  # 或其他支援 JSON 模式的 OpenAI 模型\n",
    "    response_format=SentimentAnalysisOutput,  # 直接傳遞 Pydantic 模型\n",
    ")\n",
    "response  # response 物件本身就包含了 .parsed 的結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e07ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# LLM 回傳的原始 JSON 字串內容 (如果需要查看)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2c76c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 如果需要手動解析 (雖然 parse 方法已經做了)\n",
    "response_dict = json.loads(response.choices[0].message.content)\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746eb601",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 使用 Pydantic 模型驗證並轉換字典\n",
    "sentiment_result = SentimentAnalysisOutput(**response_dict)\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95824e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Pydantic 模型提供了 model_validate_json 方法\n",
    "sentiment_result = SentimentAnalysisOutput.model_validate_json(\n",
    "    response.choices[0].message.content\n",
    ")\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cf984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接存取 .parse() 方法解析好的 Pydantic 物件\n",
    "# 這是使用 .beta.chat.completions.parse 的主要優點\n",
    "parsed_output = response.choices[0].message.parsed\n",
    "print(parsed_output)\n",
    "print(type(parsed_output))  # 型別應該是 <class '__main__.SentimentAnalysisOutput'>\n",
    "print(parsed_output.polarity)\n",
    "print(parsed_output.confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47016b38",
   "metadata": {},
   "source": [
    "# 聊天機器人（Chatbot）\n",
    "\n",
    "[Creating a chatbot fast](https://www.gradio.app/guides/creating-a-chatbot-fast)\n",
    "\n",
    "若要使用 `gr.ChatInterface()` 建立聊天應用程式，您首先應該做的是定義您的聊天函數 。最簡單的情況下，您的聊天函數應接受兩個參數：`message` 和 `history`（參數名稱可以自訂，但必須依照此順序）。\n",
    "\n",
    "* `message`：一個 `str`，代表使用者最近的訊息。\n",
    "* `history`：一個 OpenAI 風格的字典列表，其中包含 `role` 和 `content` 鍵，代表先前的對話歷史。也可能包含代表訊息元資料的其他鍵 。\n",
    "\n",
    "例如，`history` 可能如下所示：\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Paris\"}\n",
    "]\n",
    "```\n",
    "\n",
    "而下一則 `message` 將會是：\n",
    "\n",
    "```\n",
    "\"And what is its largest city?\"\n",
    "```\n",
    "\n",
    "您的聊天函數只需要回傳：\n",
    "\n",
    "一個 `str` 值，這是聊天機器人根據聊天歷史和最新訊息所做的回應，例如，在這種情況下：\n",
    "\n",
    "```\n",
    "Paris is also the largest city.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "hf_client = AsyncInferenceClient(\n",
    "    provider=\"fireworks-ai\",\n",
    "    api_key=hf_token,\n",
    ")\n",
    "\n",
    "\n",
    "async def hf_chat(message, history) -> str:\n",
    "    \"\"\"\n",
    "    使用 Hugging Face 的聊天模型進行對話。\n",
    "    \"\"\"\n",
    "    response = await hf_client.chat_completion(\n",
    "        model=\"Qwen/Qwen3-235B-A22B\",\n",
    "        messages=history + [{\"role\": \"user\", \"content\": message}],\n",
    "    )  # type: ignore\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "oai_client = AsyncOpenAI(api_key=oai_api_key)\n",
    "\n",
    "\n",
    "async def oai_chat(message, history) -> str:\n",
    "    response = await oai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=history + [{\"role\": \"user\", \"content\": message}],\n",
    "    )  # type: ignore\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=hf_chat,  # 使用 Hugging Face 的聊天模型\n",
    "    title=\"Chat with Qwen\",  # 標題\n",
    "    type=\"messages\",\n",
    ").launch(share=True)  # 啟動 Gradio 介面，並分享連結"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a68af7",
   "metadata": {},
   "source": [
    "# 測試應用程式\n",
    "接下來要打開 [`app.py`](app.py)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
