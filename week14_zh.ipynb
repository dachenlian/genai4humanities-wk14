{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44563558",
   "metadata": {},
   "source": [
    "# Week 14ï¼šæª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRAGï¼‰ã€å·¥å…·å‘¼å«èˆ‡çµæ§‹åŒ–è¼¸å‡º\n",
    "\n",
    "ä½ å¥½ï¼åœ¨æœ¬é€±çš„å¯¦é©—èª²ç¨‹ä¸­ï¼Œæˆ‘å€‘å°‡æ¢ç´¢ä¸€äº›å¼·å¤§çš„æŠ€è¡“ï¼Œä¾†æ“´å±•å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åŠŸèƒ½ã€‚æˆ‘å€‘å°‡æœƒå­¸åˆ°ï¼š\n",
    "\n",
    "1.  **åµŒå…¥ï¼ˆEmbeddingsï¼‰**:\n",
    "    * äº†è§£å¦‚ä½•ä½¿ç”¨ `sentence-transformers` å’Œ OpenAI API ä¾†å°‡æ–‡å­—è½‰æ›ç‚ºå‘é‡è¡¨ç¤ºï¼ˆåµŒå…¥ï¼‰ã€‚\n",
    "    * è¨ˆç®—æ–‡å­—ä¹‹é–“çš„ç›¸ä¼¼åº¦ã€‚\n",
    "2.  **å‘é‡è³‡æ–™åº«ï¼ˆVector Databasesï¼‰**:\n",
    "    * ä½¿ç”¨ LanceDB ä¾†å„²å­˜å’Œæª¢ç´¢æˆ‘å€‘ç”¢ç”Ÿçš„åµŒå…¥ã€‚\n",
    "    * äº†è§£å¦‚ä½•æœ‰æ•ˆåœ°æŸ¥è©¢å‘é‡è³‡æ–™åº«ä»¥æ‰¾åˆ°ç›¸é—œè³‡è¨Šã€‚\n",
    "3.  **æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRetrieval Augmented Generation - RAGï¼‰**:\n",
    "    * çµåˆå‘é‡è³‡æ–™åº«çš„æª¢ç´¢èƒ½åŠ›èˆ‡ LLM çš„ç”Ÿæˆèƒ½åŠ›ï¼Œè®“æ¨¡å‹å¯ä»¥æ ¹æ“šå¤–éƒ¨çŸ¥è­˜å›ç­”å•é¡Œã€‚\n",
    "4.  **å·¥å…·å‘¼å«ï¼ˆFunction Calling/Tool Callingï¼‰**:\n",
    "    * å­¸ç¿’å¦‚ä½•è®“ LLM å‘¼å«å¤–éƒ¨å·¥å…·æˆ–å‡½å¼ï¼ˆä¾‹å¦‚æˆ‘å€‘å»ºç«‹çš„é›»å½±è³‡æ–™åº«æŸ¥è©¢å·¥å…·ï¼‰ã€‚\n",
    "    * äº†è§£å¦‚ä½•å®šç¾©å·¥å…·çš„çµæ§‹æè¿°ï¼ˆschemaï¼‰ï¼Œä»¥åŠè™•ç†æ¨¡å‹çš„å·¥å…·å‘¼å«è«‹æ±‚ã€‚\n",
    "5.  **çµæ§‹åŒ–è¼¸å‡ºï¼ˆStructured Outputsï¼‰**:\n",
    "    * å­¸ç¿’å¦‚ä½•è®“ LLM ä»¥ç‰¹å®šçš„ JSON æ ¼å¼è¼¸å‡ºçµæœï¼Œç¢ºä¿è¼¸å‡ºçš„å¯é æ¸¬æ€§å’Œä¸€è‡´æ€§ã€‚\n",
    "\n",
    "æˆ‘å€‘å°‡æœƒä½¿ç”¨é›»å½±è³‡æ–™é›†ä½œç‚ºç¯„ä¾‹ï¼Œä¸€æ­¥ä¸€æ­¥åœ°å®Œæˆé€™äº›æ¦‚å¿µçš„å¯¦ä½œã€‚æº–å‚™å¥½äº†å—ï¼Ÿé–‹å§‹å›‰ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/dachenlian/genai4humanities-wk14.git wk14\n",
    "!rm wk14/week14.ipynb\n",
    "!mv wk14/* .\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!uv pip install --system -r pyproject.toml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013138c",
   "metadata": {},
   "source": [
    "# åŒ¯å…¥ï¼ˆImportsï¼‰\n",
    "\n",
    "é¦–å…ˆï¼Œæˆ‘å€‘éœ€è¦åŒ¯å…¥æ‰€æœ‰å¿…è¦çš„ Python å¥—ä»¶ã€‚\n",
    "`autoreload` å¯ä»¥è®“æˆ‘å€‘åœ¨ä¿®æ”¹å¤–éƒ¨ Python æª”æ¡ˆå¾Œï¼Œä¸ç”¨é‡æ–°å•Ÿå‹• Jupyteræ ¸å¿ƒå°±èƒ½è‡ªå‹•è¼‰å…¥æ›´æ–°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c1445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from enum import StrEnum\n",
    "from typing import Annotated  # ç”¨æ–¼æ›´ç²¾ç¢ºçš„å‹åˆ¥æç¤º\n",
    "\n",
    "import lancedb  # å‘é‡è³‡æ–™åº«\n",
    "import pandas as pd  # è³‡æ–™è™•ç†\n",
    "import tiktoken  # OpenAI çš„ token è¨ˆç®—å·¥å…·\n",
    "import torch  # PyTorchï¼Œç”¨æ–¼å¼µé‡é‹ç®—\n",
    "import torch.nn.functional as F  # PyTorch çš„å‡½å¼åº«ï¼Œç”¨æ–¼è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦ç­‰\n",
    "from datasets import load_dataset, load_from_disk  # Hugging Face Datasets å¥—ä»¶\n",
    "from dotenv import load_dotenv  # è®€å–ç’°å¢ƒè®Šæ•¸\n",
    "from huggingface_hub import AsyncInferenceClient  # Hugging Face æ¨è«– API å®¢æˆ¶ç«¯\n",
    "from huggingface_hub.inference._generated.types import ChatCompletionOutputToolCall\n",
    "from loguru import logger  # æ›´æ–¹ä¾¿çš„æ—¥èªŒè¨˜éŒ„\n",
    "from pydantic import BaseModel, Field  # è³‡æ–™é©—è­‰èˆ‡è¨­å®šç®¡ç†\n",
    "from openai import OpenAI, AsyncOpenAI  # OpenAI API å®¢æˆ¶ç«¯\n",
    "from openai.types.chat.chat_completion_message_tool_call import (\n",
    "    ChatCompletionMessageToolCall,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer  # å¥å­åµŒå…¥æ¨¡å‹\n",
    "from tenacity import (  # ç”¨æ–¼é‡è©¦æ©Ÿåˆ¶\n",
    "    RetryCallState,\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "\n",
    "from utils import create_tool_schema_for_function  # è‡ªè¨‚çš„å·¥å…·å‡½å¼\n",
    "from tool_types import ToolCallResult  # è‡ªè¨‚çš„å‹åˆ¥\n",
    "\n",
    "load_dotenv()  # è¼‰å…¥ .env æª”æ¡ˆä¸­çš„ç’°å¢ƒè®Šæ•¸\n",
    "\n",
    "try:\n",
    "    from google.colab import userdata  # type: ignore # å˜—è©¦å¾ Google Colab è®€å–ç§˜å¯†é‡‘é‘°\n",
    "except ImportError:\n",
    "    userdata = None\n",
    "\n",
    "load_dotenv(override=True)  # å†æ¬¡è¼‰å…¥ï¼Œç¢ºä¿ .env çš„è¨­å®šæœƒè¦†å¯«å·²å­˜åœ¨çš„ç’°å¢ƒè®Šæ•¸\n",
    "pd.set_option(\n",
    "    \"display.max_colwidth\", 0\n",
    ")  # è¨­å®š pandas DataFrame é¡¯ç¤ºæ¬„ä½çš„æœ€å¤§å¯¬åº¦ï¼ˆ0 ä»£è¡¨ä¸é™åˆ¶ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff471f3",
   "metadata": {},
   "source": [
    "# æº–å‚™è³‡æ–™é›†ï¼ˆPreparing datasetï¼‰\n",
    "\n",
    "æˆ‘å€‘å°‡ä½¿ç”¨ [TMDB 5000 Movies](https://huggingface.co/datasets/AiresPucrs/tmdb-5000-movies) è³‡æ–™é›†ã€‚\n",
    "é€™å€‹è³‡æ–™é›†åŒ…å«äº†ç´„ 5000 éƒ¨é›»å½±çš„è³‡è¨Šï¼Œä¾‹å¦‚ï¼šæ¦‚è¦½ï¼ˆoverviewï¼‰ã€é¡å‹ï¼ˆgenresï¼‰ã€é—œéµå­—ï¼ˆkeywordsï¼‰ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95891ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/AiresPucrs/tmdb-5000-movies\n",
    "ds = load_dataset(\"AiresPucrs/tmdb-5000-movies\", split=\"train\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332f7c6",
   "metadata": {},
   "source": [
    "## è³‡æ–™é è™•ç†\n",
    "æˆ‘å€‘éœ€è¦å°è³‡æ–™é›†é€²è¡Œä¸€äº›æ¸…ç†å’Œè½‰æ›ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1e5281",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ç§»é™¤ \"overview\" æ¬„ä½ç‚ºç©ºå€¼çš„é›»å½±\n",
    "ds = ds.filter(lambda x: bool(x[\"overview\"]))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example: dict) -> dict:\n",
    "    \"\"\"\n",
    "    å°å–®ç­†é›»å½±è³‡æ–™é€²è¡Œé è™•ç†ã€‚\n",
    "    - å°‡ JSON å­—ä¸²è§£æç‚º Python åˆ—è¡¨æˆ–å­—å…¸ã€‚\n",
    "    - è½‰æ›æ—¥æœŸæ ¼å¼ã€‚\n",
    "    - æå–å¹´ä»½ã€‚\n",
    "    \"\"\"\n",
    "    example[\"genres\"] = [g[\"name\"] for g in json.loads(example[\"genres\"])]\n",
    "    example[\"keywords\"] = [k[\"name\"] for k in json.loads(example[\"keywords\"])]\n",
    "    example[\"release_date\"] = datetime.datetime.strptime(\n",
    "        d if (d := example[\"release_date\"]) else \"1970-01-01\", \"%Y-%m-%d\"\n",
    "    ).date()\n",
    "    example[\"release_year\"] = example[\"release_date\"].year\n",
    "    example[\"spoken_languages\"] = [\n",
    "        sl[\"name\"] for sl in json.loads(example[\"spoken_languages\"])\n",
    "    ]\n",
    "    example[\"cast\"] = [\n",
    "        {\n",
    "            \"name\": c[\"name\"],\n",
    "            \"character\": c[\"character\"],\n",
    "        }\n",
    "        for c in json.loads(example[\"cast\"])\n",
    "    ]\n",
    "    # ä»¥ä¸‹æ˜¯è¢«è¨»è§£æ‰çš„æ¬„ä½ï¼Œæš«ä¸è™•ç†\n",
    "    # example[\"production_companies\"] = [\n",
    "    #     pc[\"name\"] for pc in json.loads(example[\"production_companies\"])\n",
    "    # ]\n",
    "    # example[\"production_countries\"] = [\n",
    "    #     pc[\"name\"] for pc in json.loads(example[\"production_countries\"])\n",
    "    # ]\n",
    "    # example[\"crew\"] = [\n",
    "    #     {\n",
    "    #         \"name\": c[\"name\"],\n",
    "    #         \"job\": c[\"job\"],\n",
    "    #     }\n",
    "    #     for c in json.loads(example[\"crew\"])\n",
    "    # ]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e7721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ .map() æ–¹æ³•å°æ•´å€‹è³‡æ–™é›†é€²è¡Œé è™•ç†\n",
    "# remove_columns æœƒç§»é™¤æŒ‡å®šçš„åŸå§‹æ¬„ä½\n",
    "# num_proc è¨­å®šäº†ä¸¦è¡Œè™•ç†çš„ç¨‹åºæ•¸é‡ï¼Œå¯ä»¥åŠ é€Ÿè™•ç†\n",
    "ds = ds.map(\n",
    "    preprocess,\n",
    "    remove_columns=[\n",
    "        \"id\",  # é›»å½±IDï¼Œé€šå¸¸ä¸éœ€è¦ä½œç‚ºç‰¹å¾µ\n",
    "        \"homepage\",  # é›»å½±ä¸»é é€£çµ\n",
    "        \"production_companies\",  # è£½ç‰‡å…¬å¸\n",
    "        \"production_countries\",  # è£½ç‰‡åœ‹å®¶\n",
    "        \"status\",  # ç™¼è¡Œç‹€æ…‹\n",
    "        \"tagline\",  # é›»å½±æ¨™èª\n",
    "        \"vote_count\",  # æŠ•ç¥¨æ•¸é‡\n",
    "        \"vote_average\",  # å¹³å‡è©•åˆ†\n",
    "        \"crew\",  # å·¥ä½œäººå“¡\n",
    "        \"original_title\",  # åŸå§‹æ¨™é¡Œ (ç¨å¾Œæœƒç”¨ 'title'ï¼Œè‹¥è¦ä¿ç•™åŸå§‹æ¨™é¡Œå¯å–æ¶ˆè¨»è§£)\n",
    "    ],\n",
    "    num_proc=4,\n",
    ")\n",
    "ds[0]  # é¡¯ç¤ºç¬¬ä¸€ç­†è™•ç†å¾Œçš„è³‡æ–™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10bf2ef",
   "metadata": {},
   "source": [
    "# åµŒå…¥ï¼ˆEmbeddingsï¼‰\n",
    "\n",
    "åµŒå…¥æ˜¯å°‡æ–‡å­—è½‰æ›ç‚ºæ•¸å€¼å‘é‡çš„éç¨‹ã€‚é€™äº›å‘é‡å¯ä»¥æ•æ‰æ–‡å­—çš„èªç¾©è³‡è¨Šï¼Œè®“æ©Ÿå™¨å¯ä»¥ç†è§£æ–‡å­—ä¹‹é–“çš„é—œä¿‚ã€‚\n",
    "æ„æ€ç›¸è¿‘çš„æ–‡å­—ï¼Œå…¶å‘é‡åœ¨å‘é‡ç©ºé–“ä¸­çš„è·é›¢ä¹Ÿæœƒæ¯”è¼ƒè¿‘ã€‚\n",
    "\n",
    "æˆ‘å€‘æœƒæ¯”è¼ƒå…©ç¨®ç”¢ç”ŸåµŒå…¥çš„æ–¹å¼ï¼š\n",
    "1.  **sentence-transformers**: ä¸€å€‹é–‹æºçš„ Python å¥—ä»¶ï¼Œæä¾›äº†è¨±å¤šé è¨“ç·´å¥½çš„æ¨¡å‹ï¼Œå¯ä»¥åœ¨æœ¬æ©Ÿç«¯åŸ·è¡Œã€‚\n",
    "2.  **OpenAI API**: OpenAI æä¾›çš„ä»˜è²»æœå‹™ï¼Œå¯ä»¥é€é API å–å¾—é«˜å“è³ªçš„æ–‡å­—åµŒå…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa89632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"I want to watch an exciting superhero movie\",  # æˆ‘æƒ³çœ‹ä¸€éƒ¨åˆºæ¿€çš„è¶…ç´šè‹±é›„é›»å½±\n",
    "    \"æˆ‘æƒ³çœ‹ä¸€éƒ¨è¶…ç´šè‹±é›„é›»å½±\",  # ä¸­æ–‡æŸ¥è©¢\n",
    "]\n",
    "\n",
    "movies = [\n",
    "    \"A movie about a group of friends who go on a road trip\",  # ä¸€éƒ¨é—œæ–¼ä¸€ç¾¤æœ‹å‹å…¬è·¯æ—…è¡Œçš„é›»å½±\n",
    "    \"A romantic comedy about a couple who meet at a wedding\",  # ä¸€éƒ¨é—œæ–¼ä¸€å°åœ¨å©šç¦®ä¸Šç›¸é‡çš„æƒ…ä¾¶çš„æµªæ¼«å–œåŠ‡\n",
    "    \"An autobiography of George Washington, the first president of the United States\",  # ç¾åœ‹ç¬¬ä¸€ä»»ç¸½çµ±å–¬æ²»è¯ç››é “çš„è‡ªå‚³\n",
    "    \"Spider-Man is fighting against the Green Goblin in another universe\",  # èœ˜è››äººåœ¨å¦ä¸€å€‹å®‡å®™å°æŠ—ç¶ æƒ¡é­”\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f1c42",
   "metadata": {},
   "source": [
    "## sentence-transformers\n",
    "\n",
    "* [å®˜æ–¹æ–‡ä»¶](https://sbert.net/)\n",
    "* æ”¯æ´ `sentence-transformers` çš„æ¨¡å‹ï¼šhttps://huggingface.co/models?library=sentence-transformers\n",
    "* ç”¨æ–¼ `sentence-similarity`ï¼ˆå¥å­ç›¸ä¼¼åº¦ï¼‰ä»»å‹™çš„æ¨¡å‹ï¼šhttps://huggingface.co/models?pipeline_tag=sentence-similarity\n",
    "\n",
    "æˆ‘å€‘å°‡ä½¿ç”¨ `paraphrase-multilingual-MiniLM-L12-v2` æ¨¡å‹ï¼Œå®ƒæ”¯æ´å¤šç¨®èªè¨€ï¼ŒåŒ…å«è‹±æ–‡å’Œä¸­æ–‡ã€‚\n",
    "`device=\"cpu\"` è¡¨ç¤ºæˆ‘å€‘å°‡åœ¨ CPU ä¸ŠåŸ·è¡Œæ¨¡å‹ã€‚å¦‚æœæœ‰ GPUï¼Œå¯ä»¥æ”¹ç‚º `\"cuda\"`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58e520f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b78690",
   "metadata": {},
   "source": [
    "### è¨ˆç®—åµŒå…¥ï¼ˆCompute embeddingsï¼‰\n",
    "\n",
    "ä½¿ç”¨ `embedder.encode()` æ–¹æ³•å°‡æ–‡å­—è½‰æ›ç‚ºåµŒå…¥å‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embeddings = embedder.encode(queries)\n",
    "movie_embeddings = embedder.encode(movies)\n",
    "print(\n",
    "    query_embeddings.shape, movie_embeddings.shape\n",
    ")  # .shape é¡¯ç¤ºå‘é‡çš„ç¶­åº¦ (æ•¸é‡, ç¶­åº¦å¤§å°)\n",
    "print(f\"Query: {query_embeddings[0][:5]}\")  # é¡¯ç¤ºç¬¬ä¸€å€‹æŸ¥è©¢å‘é‡çš„å‰5å€‹ç¶­åº¦å€¼\n",
    "print(f\"Movie: {movie_embeddings[0][:5]}\")  # é¡¯ç¤ºç¬¬ä¸€å€‹é›»å½±æè¿°å‘é‡çš„å‰5å€‹ç¶­åº¦å€¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b195ce",
   "metadata": {},
   "source": [
    "### è¨ˆç®—ç›¸ä¼¼åº¦ä¸¦æ“·å–å‰ K å€‹ï¼ˆComputing similarity + retrieving top kï¼‰\n",
    "\n",
    "æˆ‘å€‘å¯ä»¥ä½¿ç”¨ `embedder.similarity()` æ–¹æ³•ä¾†è¨ˆç®—å…©çµ„åµŒå…¥ä¹‹é–“çš„é¤˜å¼¦ç›¸ä¼¼åº¦ã€‚\n",
    "é¤˜å¼¦ç›¸ä¼¼åº¦çš„å€¼ä»‹æ–¼ -1 å’Œ 1 ä¹‹é–“ï¼Œè¶Šæ¥è¿‘ 1 ä»£è¡¨è¶Šç›¸ä¼¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945142c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨ˆç®—æŸ¥è©¢åµŒå…¥å’Œé›»å½±åµŒå…¥ä¹‹é–“çš„é¤˜å¼¦ç›¸ä¼¼åº¦\n",
    "similarities = embedder.similarity(query_embeddings, movie_embeddings)\n",
    "similarities  # è¼¸å‡ºä¸€å€‹çŸ©é™£ï¼Œåˆ—ä»£è¡¨é›»å½±ï¼Œæ¬„ä»£è¡¨æŸ¥è©¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = \"\\033[33m\"  # ANSI escape codeï¼Œè®“æ–‡å­—é¡¯ç¤ºç‚ºé»ƒè‰²\n",
    "END = \"\\033[0m\"  # ANSI escape codeï¼Œé‡è¨­æ–‡å­—é¡è‰²\n",
    "# è¼¸å‡ºæ‰€æœ‰æŸ¥è©¢èˆ‡é›»å½±çš„ç›¸ä¼¼åº¦åˆ†æ•¸\n",
    "for idx_i, sentence1 in enumerate(queries):\n",
    "    print(sentence1)\n",
    "    for idx_j, sentence2 in enumerate(movies):\n",
    "        print(\n",
    "            f\" - {sentence2: <30}: {YELLOW}{similarities[idx_i][idx_j]:.4f}{END}\"\n",
    "        )  # :.4f è¡¨ç¤ºæ ¼å¼åŒ–ç‚ºå°æ•¸é»å¾Œ4ä½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa62eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.topk() å¯ä»¥æ‰¾åˆ°å¼µé‡ä¸­æœ€å¤§æˆ–æœ€å°çš„ k å€‹å…ƒç´ åŠå…¶ç´¢å¼•\n",
    "# similarities[0] æ˜¯ç¬¬ä¸€å€‹æŸ¥è©¢èˆ‡æ‰€æœ‰é›»å½±çš„ç›¸ä¼¼åº¦\n",
    "torch.topk(similarities[0], k=4)  # k=4 è¡¨ç¤ºæ‰¾å‡ºæœ€ç›¸ä¼¼çš„4éƒ¨é›»å½±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1014f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼¸å‡ºæ¯å€‹æŸ¥è©¢æœ€ç›¸ä¼¼çš„ k éƒ¨é›»å½±\n",
    "for idx_i, sentence1 in enumerate(queries):\n",
    "    print(sentence1)\n",
    "    # torch.topk().indices æœƒå›å‚³å‰ k å€‹æœ€ç›¸ä¼¼é›»å½±çš„ç´¢å¼•\n",
    "    for idx_j in torch.topk(similarities[idx_i], k=4).indices:\n",
    "        print(f\" - {movies[idx_j]: <30}: {YELLOW}{similarities[idx_i][idx_j]:.4f}{END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c72fe",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "[å®˜æ–¹æ–‡ä»¶](https://platform.openai.com/docs/guides/embeddings?lang=python)\n",
    "\n",
    "ä½¿ç”¨ OpenAI çš„åµŒå…¥æ¨¡å‹é€šå¸¸å¯ä»¥å¾—åˆ°æ›´å¥½çš„æ•ˆæœï¼Œä½†éœ€è¦ API é‡‘é‘°ä¸”æœ‰è²»ç”¨ã€‚\n",
    "\n",
    "æˆ‘å€‘å°‡ä½¿ç”¨ `text-embedding-3-small` æ¨¡å‹ï¼Œå®ƒåœ¨æˆæœ¬å’Œæ•ˆèƒ½ä¹‹é–“å–å¾—äº†ä¸éŒ¯çš„å¹³è¡¡ã€‚\n",
    "\n",
    "![](https://i.redd.it/lpf0u9nbj7w41.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156cbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key and userdata:\n",
    "    # å¦‚æœåœ¨ Google Colab ç’°å¢ƒï¼Œå˜—è©¦å¾ userdata å–å¾— API é‡‘é‘°\n",
    "    api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š\")\n",
    "\n",
    "# ä½¿ç”¨ AsyncOpenAI é€²è¡ŒéåŒæ­¥ API å‘¼å«ï¼Œå¯ä»¥æé«˜æ•ˆç‡\n",
    "client = AsyncOpenAI(api_key=api_key, max_retries=5)  # max_retries è¨­å®šæœ€å¤§é‡è©¦æ¬¡æ•¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf1b53",
   "metadata": {},
   "source": [
    "### è¨ˆç®—åµŒå…¥ï¼ˆCompute embeddingsï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ await ç­‰å¾…éåŒæ­¥å‡½å¼çš„çµæœ\n",
    "res = await client.embeddings.create(input=queries[0], model=\"text-embedding-3-small\")\n",
    "embedding = res.data[0].embedding\n",
    "print(len(embedding))  # é¡¯ç¤ºåµŒå…¥å‘é‡çš„ç¶­åº¦å¤§å°\n",
    "print(embedding[:5])  # é¡¯ç¤ºå‘é‡çš„å‰5å€‹ç¶­åº¦å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.usage.total_tokens é¡¯ç¤ºé€™æ¬¡ API å‘¼å«æ¶ˆè€—çš„ token æ•¸é‡\n",
    "print(f\"Total tokens: {res.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d249a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ asyncio.gather ä¸¦è¡Œè™•ç†å¤šå€‹ API å‘¼å«ï¼Œä»¥ç¯€çœæ™‚é–“\n",
    "_query_embeddings = await asyncio.gather(\n",
    "    *[\n",
    "        client.embeddings.create(input=query, model=\"text-embedding-3-small\")\n",
    "        for query in queries\n",
    "    ]\n",
    ")\n",
    "# å°‡ API å›å‚³çš„åµŒå…¥è½‰æ›ç‚º PyTorch å¼µé‡ (Tensor)\n",
    "query_embeddings = torch.Tensor(\n",
    "    [embedding.data[0].embedding for embedding in _query_embeddings]\n",
    ")\n",
    "\n",
    "_movie_embeddings = await asyncio.gather(\n",
    "    *[\n",
    "        client.embeddings.create(input=movie, model=\"text-embedding-3-small\")\n",
    "        for movie in movies\n",
    "    ]\n",
    ")\n",
    "movie_embeddings = torch.Tensor(\n",
    "    [embedding.data[0].embedding for embedding in _movie_embeddings]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829db4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_embeddings å·²ç¶“æ˜¯ PyTorch å¼µé‡äº†ï¼Œé€™è£¡å†æ¬¡è½‰æ› torch.Tensor(movie_embeddings) æ˜¯å¤šé¤˜çš„\n",
    "# ä½†ç‚ºäº†ä¿æŒèˆ‡ notebook ä¸€è‡´ï¼Œæš«ä¸ä¿®æ”¹ã€‚\n",
    "torch.Tensor(movie_embeddings)  # é€™è£¡çš„ movie_embeddings å·²ç¶“æ˜¯ torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b0d3a4",
   "metadata": {},
   "source": [
    "### è¨ˆç®—ç›¸ä¼¼åº¦ä¸¦æ“·å–å‰ K å€‹ï¼ˆComputing similarity + retrieving top kï¼‰\n",
    "\n",
    "æˆ‘å€‘ä½¿ç”¨ `torch.nn.functional.cosine_similarity` (åˆ¥åç‚º `F.cosine_similarity`) ä¾†è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦ã€‚\n",
    "`unsqueeze()` æ–¹æ³•ç”¨æ–¼å¢åŠ å¼µé‡çš„ç¶­åº¦ï¼Œä»¥ç¬¦åˆ `cosine_similarity` çš„è¼¸å…¥è¦æ±‚ã€‚\n",
    "`dim=2` è¡¨ç¤ºæ²¿è‘—ç¬¬ä¸‰å€‹ç¶­åº¦ï¼ˆç´¢å¼•ç‚º2ï¼‰è¨ˆç®—ç›¸ä¼¼åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = F.cosine_similarity(\n",
    "    query_embeddings.unsqueeze(1),  # (num_queries, 1, embedding_dim)\n",
    "    movie_embeddings.unsqueeze(0),  # (1, num_movies, embedding_dim)\n",
    "    dim=2,  # çµæœç¶­åº¦ (num_queries, num_movies)\n",
    ")\n",
    "similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4567c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = \"\\033[33m\"\n",
    "END = \"\\033[0m\"\n",
    "for idx_i, sentence1 in enumerate(queries):\n",
    "    print(sentence1)\n",
    "    for idx_j in torch.topk(similarities[idx_i], k=4).indices:\n",
    "        print(f\" - {movies[idx_j]: <30}: {YELLOW}{similarities[idx_i][idx_j]:.4f}{END}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94acad8",
   "metadata": {},
   "source": [
    "### è¨ˆç®— token æ•¸é‡èˆ‡åƒ¹æ ¼ï¼ˆCalculate tokens and priceï¼‰\n",
    "\n",
    "[OpenAI åƒ¹æ ¼](https://platform.openai.com/docs/pricing)\n",
    "\n",
    "ä½¿ç”¨ `tiktoken` å¥—ä»¶å¯ä»¥è¨ˆç®— OpenAI æ¨¡å‹è™•ç†æ–‡å­—æ™‚æœƒæ¶ˆè€—å¤šå°‘ tokenã€‚\n",
    "ä¸åŒçš„æ¨¡å‹æœ‰ä¸åŒçš„è¨ˆåƒ¹æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d186daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å–å¾— \"text-embedding-3-small\" æ¨¡å‹å°æ‡‰çš„ç·¨ç¢¼å™¨\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0370e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = enc.encode(queries[0])  # å°‡æ–‡å­—ç·¨ç¢¼ç‚º token ID åˆ—è¡¨\n",
    "print(f\"Total tokens: {len(encoded)}\")\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edebe03",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ä¸åŒåµŒå…¥æ¨¡å‹çš„æ¯ç™¾è¬ token åƒ¹æ ¼ (ç¾å…ƒ)\n",
    "model_to_price = {\n",
    "    \"text-embedding-3-small\": 0.02,  # åƒ¹æ ¼è¼ƒä½\n",
    "    \"text-embedding-3-large\": 0.13,  # åƒ¹æ ¼è¼ƒé«˜ï¼Œä½†é€šå¸¸æ•ˆæœæ›´å¥½\n",
    "}\n",
    "\n",
    "\n",
    "def get_token_count_and_price(\n",
    "    texts: list[str], model: str = \"text-embedding-3-small\"\n",
    ") -> tuple[int, float]:\n",
    "    \"\"\"\n",
    "    è¨ˆç®—ä¸€æ‰¹æ–‡å­—çš„ç¸½ token æ•¸å’Œé ä¼°åƒ¹æ ¼ã€‚\n",
    "    \"\"\"\n",
    "    if model not in model_to_price:\n",
    "        raise ValueError(f\"ä¸æ”¯æ´çš„æ¨¡å‹ {model}\")\n",
    "    enc = tiktoken.encoding_for_model(model)\n",
    "    # encode_batch å¯ä»¥ä¸€æ¬¡è™•ç†å¤šç­†æ–‡å­—ï¼Œæ•ˆç‡è¼ƒé«˜\n",
    "    token_count = sum(len(e) for e in enc.encode_batch(texts))\n",
    "    price_per_1m_tokens = model_to_price[model]\n",
    "    price = (token_count / 1_000_000) * price_per_1m_tokens\n",
    "    return token_count, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a256c4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ä¼°ç®— movies åˆ—è¡¨é‡è¤‡10æ¬¡çš„ token æ•¸å’Œåƒ¹æ ¼\n",
    "get_token_count_and_price(movies * 10, model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0884fd4",
   "metadata": {},
   "source": [
    "### è™•ç†é€Ÿç‡é™åˆ¶ï¼ˆHandling rate limitsï¼‰\n",
    "\n",
    "ç•¶çŸ­æ™‚é–“å…§å¤§é‡å‘¼å« API æ™‚ï¼Œå¯èƒ½æœƒè§¸ç™¼é€Ÿç‡é™åˆ¶ (rate limits)ã€‚\n",
    "`tenacity` å¥—ä»¶å¯ä»¥å¹«åŠ©æˆ‘å€‘å¯¦ä½œé‡è©¦æ©Ÿåˆ¶ï¼Œä¾‹å¦‚æŒ‡æ•¸é€€é¿ (exponential backoff)ã€‚\n",
    "æŒ‡æ•¸é€€é¿æ˜¯æŒ‡æ¯æ¬¡é‡è©¦çš„ç­‰å¾…æ™‚é–“æœƒé€æ¼¸å¢åŠ ï¼Œé¿å…å° API é€ æˆéå¤§è² è¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e30c8e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def log_backoff_attempt(retry_state: RetryCallState) -> None:\n",
    "    \"\"\"\n",
    "    åœ¨æ¯æ¬¡é‡è©¦å‰è¨˜éŒ„æ—¥èªŒã€‚\n",
    "    \"\"\"\n",
    "    attempt_num = retry_state.attempt_number  # ç¬¬å¹¾æ¬¡é‡è©¦\n",
    "    exception = (\n",
    "        retry_state.outcome.exception() if retry_state.outcome else \"N/A\"\n",
    "    )  # è§¸ç™¼é‡è©¦çš„ä¾‹å¤–\n",
    "    wait_time = (\n",
    "        retry_state.next_action.sleep if retry_state.next_action else 0.0\n",
    "    )  # ä¸‹æ¬¡é‡è©¦å‰çš„ç­‰å¾…æ™‚é–“\n",
    "    func_name = (\n",
    "        retry_state.fn.__name__ if retry_state.fn else \"N/A\"\n",
    "    )  # æ­£åœ¨é‡è©¦çš„å‡½å¼åç¨±\n",
    "\n",
    "    logger.info(\n",
    "        f\"å‡½å¼ '{func_name}' é€€é¿ä¸­ï¼š \"\n",
    "        f\"ç¬¬ {attempt_num} æ¬¡å˜—è©¦å›  '{exception.__class__.__name__}: {exception}' å¤±æ•—ã€‚ \"\n",
    "        f\"ä¸‹æ¬¡å˜—è©¦å‰ç­‰å¾… {wait_time:.2f} ç§’ã€‚\"\n",
    "    )\n",
    "\n",
    "\n",
    "@retry(\n",
    "    wait=wait_random_exponential(\n",
    "        min=1, max=60\n",
    "    ),  # ç­‰å¾…æ™‚é–“ç‚ºæŒ‡æ•¸å¢åŠ ï¼Œæœ€å°1ç§’ï¼Œæœ€å¤§60ç§’ï¼Œä¸¦åŠ å…¥éš¨æ©Ÿæ€§\n",
    "    stop=stop_after_attempt(6),  # æœ€å¤šé‡è©¦6æ¬¡\n",
    "    before_sleep=log_backoff_attempt,  # æ¯æ¬¡é‡è©¦å‰å‘¼å« log_backoff_attempt\n",
    ")\n",
    "async def embedding_with_backoff(**kwargs):\n",
    "    \"\"\"\n",
    "    å¸¶æœ‰æŒ‡æ•¸é€€é¿é‡è©¦æ©Ÿåˆ¶çš„åµŒå…¥å‡½å¼ã€‚\n",
    "    \"\"\"\n",
    "    return await client.embeddings.create(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581c60b",
   "metadata": {},
   "source": [
    "# è¨­å®šå‘é‡è³‡æ–™åº«ï¼ˆSetting up a vector databaseï¼‰\n",
    "\n",
    "[LanceDB æ–‡ä»¶](https://lancedb.github.io/lancedb/basic/)\n",
    "\n",
    "å‘é‡è³‡æ–™åº«å°ˆé–€ç”¨æ–¼å„²å­˜å’Œæª¢ç´¢å‘é‡åµŒå…¥ã€‚\n",
    "LanceDB æ˜¯ä¸€å€‹é–‹æºçš„ã€ç„¡ä¼ºæœå™¨çš„å‘é‡è³‡æ–™åº«ï¼Œå¾ˆå®¹æ˜“åœ¨æœ¬æ©Ÿç«¯ä½¿ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9098a",
   "metadata": {},
   "source": [
    "## å»ºç«‹ LanceDB è¡¨æ ¼ï¼ˆCreating a LanceDB tableï¼‰\n",
    "\n",
    "æˆ‘å€‘å°‡ä½¿ç”¨é›»å½±çš„ \"overview\"ï¼ˆæ¦‚è¦½ï¼‰æ¬„ä½ä¾†ç”¢ç”ŸåµŒå…¥ä¸¦å­˜å…¥è³‡æ–™åº«ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds æ˜¯æˆ‘å€‘ä¹‹å‰é è™•ç†å¥½çš„ Hugging Face Dataset ç‰©ä»¶\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "overviews = ds[\"overview\"]  # å–å‡ºæ‰€æœ‰é›»å½±çš„æ¦‚è¦½æ–‡å­—\n",
    "print(len(overviews))\n",
    "overviews[:5]  # é¡¯ç¤ºå‰5ç­†æ¦‚è¦½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.features  # é¡¯ç¤ºè³‡æ–™é›†çš„æ¬„ä½è³‡è¨Šå’Œå‹åˆ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a25952",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ sentence-transformers ç”¢ç”ŸåµŒå…¥\n",
    "\n",
    "æˆ‘å€‘å°‡ä½¿ç”¨å…ˆå‰è¼‰å…¥çš„ `sentence-transformers` æ¨¡å‹ä¾†ç‚ºæ‰€æœ‰é›»å½±æ¦‚è¦½ç”¢ç”ŸåµŒå…¥ã€‚\n",
    "é€™ä¸€æ­¥åœ¨æœ¬æ©ŸåŸ·è¡Œï¼Œä¸éœ€è¦ API é‡‘é‘°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e49ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç‚ºæ‰€æœ‰é›»å½±æ¦‚è¦½ç”¢ç”ŸåµŒå…¥\n",
    "# é€™ä¸€è¡Œç¨‹å¼ç¢¼åŸ·è¡Œæ™‚é–“å¯èƒ½æœƒæ¯”è¼ƒä¹…ï¼Œå–æ±ºæ–¼è³‡æ–™é‡å’Œç¡¬é«”æ•ˆèƒ½\n",
    "overview_embeddings = embedder.encode(overviews)\n",
    "overview_embeddings[0][:5]  # é¡¯ç¤ºç¬¬ä¸€å€‹æ¦‚è¦½åµŒå…¥çš„å‰5å€‹ç¶­åº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ec4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "overview_embeddings.shape  # (é›»å½±æ•¸é‡, åµŒå…¥ç¶­åº¦)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e674d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡ç”¢ç”Ÿçš„åµŒå…¥å‘é‡ä½œç‚ºæ–°çš„ä¸€æ¬„ \"vector\" åŠ å…¥åˆ°æˆ‘å€‘çš„è³‡æ–™é›†ä¸­\n",
    "# .tolist() æ˜¯å› ç‚º Hugging Face Datasets åœ¨æ–°å¢æ¬„ä½æ™‚ï¼Œè‹¥è³‡æ–™æ˜¯ numpy arrayï¼Œé€šå¸¸éœ€è¦è½‰æˆ list\n",
    "ds = ds.add_column(name=\"vector\", column=overview_embeddings.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29912e95",
   "metadata": {},
   "source": [
    "### å°‡çµæœå„²å­˜åˆ°ç£ç¢Ÿï¼ˆSave results to diskï¼‰\n",
    "\n",
    "è™•ç†å®Œçš„è³‡æ–™é›†å¯ä»¥å„²å­˜èµ·ä¾†ï¼Œæ–¹ä¾¿ä¹‹å¾Œè¼‰å…¥ä½¿ç”¨ï¼Œé¿å…é‡è¤‡é‹ç®—ã€‚\n",
    "Hugging Face Datasets æä¾›äº† `save_to_disk` æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c63aef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.save_to_disk(\"./data/dataset_processed\")  # å°‡è³‡æ–™é›†å„²å­˜åˆ°æŒ‡å®šè·¯å¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f5419",
   "metadata": {},
   "source": [
    "#### å°‡çµæœå„²å­˜åˆ° Google Driveï¼ˆSave results to Google Driveï¼‰\n",
    "\n",
    "å¦‚æœä½ åœ¨ Google Colab ç’°å¢ƒä¸­åŸ·è¡Œï¼Œå¯ä»¥å°‡è³‡æ–™å„²å­˜åˆ° Google Driveï¼Œæ–¹ä¾¿æŒä¹…åŒ–å„²å­˜ã€‚\n",
    "é€™æ®µç¨‹å¼ç¢¼åªæœ‰åœ¨ Colab ç’°å¢ƒä¸­æ‰éœ€è¦åŸ·è¡Œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount(\"/content/drive\") # æ›è¼‰ Google Drive\n",
    "# !mkdir -p \"/content/drive/My Drive/genai4h-wk14\" # åœ¨ Google Drive å»ºç«‹è³‡æ–™å¤¾\n",
    "# !cp -r \"./data/dataset_processed\" \"/content/drive/My Drive/genai4h-wk14/\" # å°‡è™•ç†å¥½çš„è³‡æ–™è¤‡è£½åˆ° Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d52a7",
   "metadata": {},
   "source": [
    "### å¾ç£ç¢Ÿè¼‰å…¥çµæœï¼ˆLoad results from diskï¼‰\n",
    "\n",
    "ä½¿ç”¨ `load_from_disk` å¯ä»¥å¿«é€Ÿè¼‰å…¥ä¹‹å‰å„²å­˜çš„è³‡æ–™é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a73453",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\n",
    "    \"./data/dataset_processed\"\n",
    ")  # å¾ç£ç¢Ÿè¼‰å…¥è™•ç†å¥½çš„è³‡æ–™é›† (æ³¨æ„è·¯å¾‘èˆ‡å„²å­˜æ™‚ä¸€è‡´)\n",
    "ds[0]  # æª¢æŸ¥è¼‰å…¥çš„è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d3fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡ Hugging Face Dataset è½‰æ›ç‚º pandas DataFrameï¼Œæ–¹ä¾¿å¾ŒçºŒæ“ä½œ\n",
    "df = ds.to_pandas()\n",
    "df.iloc[0]  # é¡¯ç¤º DataFrame çš„ç¬¬ä¸€åˆ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00208c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€£æ¥åˆ° LanceDB è³‡æ–™åº«\n",
    "# å¦‚æœ \"./data/lance_db\" è·¯å¾‘ä¸å­˜åœ¨ï¼ŒLanceDB æœƒè‡ªå‹•å»ºç«‹å®ƒ\n",
    "db = lancedb.connect(\"./data/lance_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef520b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ä¸€å€‹åç‚º \"movies\" çš„è¡¨æ ¼\n",
    "# data=df è¡¨ç¤ºä½¿ç”¨æˆ‘å€‘çš„ DataFrame ä½œç‚ºè³‡æ–™ä¾†æº\n",
    "# mode=\"overwrite\" è¡¨ç¤ºå¦‚æœ \"movies\" è¡¨æ ¼å·²å­˜åœ¨ï¼Œå‰‡è¦†å¯«å®ƒ\n",
    "tbl = db.create_table(\"movies\", data=df, mode=\"overwrite\")\n",
    "# å° \"overview\" æ¬„ä½å»ºç«‹å…¨æ–‡æª¢ç´¢ (FTS) ç´¢å¼•ï¼Œå¯ä»¥åŠ é€Ÿé—œéµå­—æœå°‹\n",
    "# æ³¨æ„ï¼šé€™è£¡çš„ FTS ç´¢å¼•æ˜¯é‡å° \"overview\" é€™å€‹æ–‡å­—æ¬„ä½ï¼Œè€Œä¸æ˜¯å‘é‡æ¬„ä½\n",
    "tbl.create_fts_index(\"overview\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86589b85",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ OpenAI ç”¢ç”ŸåµŒå…¥ï¼ˆOpenAIï¼‰\n",
    "\n",
    "[åµŒå…¥å¤ªæ…¢ï¼Ÿ(Slow embeddings?)](https://community.openai.com/t/embeddings-api-extremely-slow/1135044)\n",
    "\n",
    "å¦‚æœé¸æ“‡ä½¿ç”¨ OpenAI API ä¾†ç”¢ç”Ÿæ‰€æœ‰é›»å½±æ¦‚è¦½çš„åµŒå…¥ï¼Œè«‹æ³¨æ„ï¼š\n",
    "1.  **è²»ç”¨**ï¼šè³‡æ–™é‡å¤§æ™‚ï¼Œè²»ç”¨å¯èƒ½æœƒæ¯”è¼ƒé«˜ã€‚\n",
    "2.  **æ™‚é–“**ï¼šå³ä½¿ä½¿ç”¨ `asyncio.gather` å’Œé‡è©¦æ©Ÿåˆ¶ï¼Œè™•ç†å¤§é‡æ–‡å­—ä¹Ÿå¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ã€‚\n",
    "\n",
    "ä»¥ä¸‹ç¨‹å¼ç¢¼æ˜¯ä½¿ç”¨ OpenAI ç”¢ç”ŸåµŒå…¥çš„ç¯„ä¾‹ã€‚å¦‚æœå…ˆå‰å·²ä½¿ç”¨ `sentence-transformers` ç”¢ç”Ÿä¸¦å„²å­˜äº†åµŒå…¥ï¼Œå¯ä»¥è·³éé€™éƒ¨åˆ†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5aea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "overviews = ds[\"overview\"]  # å†æ¬¡å–å¾—é›»å½±æ¦‚è¦½\n",
    "# è¨ˆç®—ä½¿ç”¨ OpenAI \"text-embedding-3-small\" æ¨¡å‹è™•ç†æ‰€æœ‰æ¦‚è¦½æ‰€éœ€çš„ token æ•¸å’Œé ä¼°åƒ¹æ ¼\n",
    "get_token_count_and_price(overviews, model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb4ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # è¨»è§£æ‰ä»¥ä¸‹å€å¡Šï¼Œå› ç‚ºæˆ‘å€‘å·²ç¶“ä½¿ç”¨ sentence-transformers ç”¢ç”ŸåµŒå…¥\n",
    "# # å¦‚æœè¦æ”¹ç”¨ OpenAIï¼Œè«‹å–æ¶ˆè¨»è§£ä¸¦åŸ·è¡Œ\n",
    "#\n",
    "# # ä½¿ç”¨å¸¶æœ‰é‡è©¦æ©Ÿåˆ¶çš„ embedding_with_backoff å‡½å¼ï¼Œç‚ºæ¯å€‹æ¦‚è¦½æ–‡å­—ç”¢ç”ŸåµŒå…¥\n",
    "# _overview_embeddings = await asyncio.gather(\n",
    "#     *[\n",
    "#         embedding_with_backoff(input=overview, model=\"text-embedding-3-small\")\n",
    "#         # client.embeddings.create(input=overview, model=\"text-embedding-3-small\") # ä¸å¸¶é‡è©¦çš„ç‰ˆæœ¬\n",
    "#         for overview in overviews\n",
    "#     ]\n",
    "# )\n",
    "# overview_embeddings = [\n",
    "#     embedding.data[0].embedding for embedding in _overview_embeddings\n",
    "# ]\n",
    "# overview_embeddings[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09fe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # è¨»è§£æ‰ä»¥ä¸‹å€å¡Šï¼Œå› ç‚ºæˆ‘å€‘å·²ç¶“ä½¿ç”¨ sentence-transformers ç”¢ç”ŸåµŒå…¥\n",
    "# df = ds.to_pandas() # å¦‚æœå‰é¢æ²’æœ‰è½‰ DataFrameï¼Œé€™è£¡éœ€è¦è½‰æ›\n",
    "# df[\"vector\"] = overview_embeddings # å°‡ OpenAI ç”¢ç”Ÿçš„åµŒå…¥å­˜åˆ° DataFrame çš„ \"vector\" æ¬„\n",
    "# # ä¹‹å¾Œå¯ä»¥åƒ sentence-transformers çš„æƒ…æ³ä¸€æ¨£ï¼Œç”¨é€™å€‹ df å»ºç«‹ LanceDB è¡¨æ ¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569f3ff",
   "metadata": {},
   "source": [
    "# å‘é‡æœå°‹ï¼ˆVector searchï¼‰\n",
    "\n",
    "* [å‘é‡æœå°‹ (Vector search)](https://lancedb.github.io/lancedb/search/)\n",
    "* [æ··åˆæœå°‹ (Hybrid search)](https://lancedb.github.io/lancedb/hybrid_search/hybrid_search/) (çµåˆå‘é‡æœå°‹å’Œé—œéµå­—æœå°‹)\n",
    "* [é—œéµå­—æœå°‹ (Keyword search)](https://lancedb.github.io/lancedb/fts/) (éœ€è¦å…ˆå°æ–‡å­—æ¬„ä½å»ºç«‹ FTS ç´¢å¼•)\n",
    "\n",
    "æ··åˆæœå°‹å’Œé—œéµå­—æœå°‹å°æ–¼è·¨èªè¨€æœå°‹çš„æ•ˆæœå¯èƒ½ä¸å¦‚ç´”å‘é‡æœå°‹ï¼ˆå¦‚æœä½¿ç”¨çš„åµŒå…¥æ¨¡å‹æ”¯æ´å¤šèªè¨€ï¼‰ã€‚\n",
    "å‘é‡æœå°‹çš„æ ¸å¿ƒæ˜¯è¨ˆç®—æŸ¥è©¢å‘é‡èˆ‡è³‡æ–™åº«ä¸­æ‰€æœ‰å‘é‡çš„ç›¸ä¼¼åº¦ï¼Œä¸¦æ‰¾å‡ºæœ€ç›¸ä¼¼çš„çµæœã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1243e1c",
   "metadata": {},
   "source": [
    "## è¼‰å…¥åµŒå…¥æ¨¡å‹ï¼ˆLoad embedding modelï¼‰\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "âš ï¸ **è­¦å‘Š**ï¼šå¿…é ˆä½¿ç”¨èˆ‡å»ºç«‹è³‡æ–™åº«æ™‚ç›¸åŒçš„åµŒå…¥æ¨¡å‹ä¾†ç”¢ç”ŸæŸ¥è©¢å‘é‡ã€‚å¦å‰‡ï¼Œå‘é‡ç©ºé–“ä¸ä¸€è‡´ï¼Œæœå°‹çµæœæœƒæ²’æœ‰æ„ç¾©ã€‚\n",
    "</div>\n",
    "\n",
    "å› ç‚ºæˆ‘å€‘ä¹‹å‰æ˜¯ç”¨ `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` å»ºç«‹çš„ LanceDB è¡¨æ ¼ï¼Œ\n",
    "æ‰€ä»¥é€™è£¡ä¹Ÿè¦è¼‰å…¥åŒä¸€å€‹æ¨¡å‹ä¾†ç”¢ç”ŸæŸ¥è©¢çš„åµŒå…¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a937630",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6f1c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€£æ¥åˆ°å…ˆå‰å»ºç«‹çš„ LanceDB è³‡æ–™åº«ä¸¦é–‹å•Ÿ \"movies\" è¡¨æ ¼\n",
    "db = lancedb.connect(\"./data/lance_db/\")\n",
    "tbl = db.open_table(\"movies\")\n",
    "# å†æ¬¡ç¢ºèª \"overview\" æ¬„ä½æœ‰ FTS ç´¢å¼• (å¦‚æœä¹‹å‰å·²å»ºç«‹ï¼Œreplace=True æœƒè¦†å¯«)\n",
    "# é€™ä¸€æ­¥é©Ÿæ˜¯ç‚ºäº†ç¢ºä¿ FTS ç´¢å¼•å­˜åœ¨ï¼Œå¦‚æœåªæ˜¯åšå‘é‡æœå°‹ï¼Œå¯ä»¥ä¸åŸ·è¡Œã€‚\n",
    "tbl.create_fts_index(\"overview\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb214e",
   "metadata": {},
   "source": [
    "## åµŒå…¥æŸ¥è©¢ï¼ˆEmbed the queryï¼‰\n",
    "\n",
    "å°‡ä½¿ç”¨è€…çš„æŸ¥è©¢æ–‡å­—è½‰æ›ç‚ºåµŒå…¥å‘é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9199a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_en = \"I want to watch a romantic comedy\"  # è‹±æ–‡æŸ¥è©¢ï¼šæˆ‘æƒ³çœ‹ä¸€éƒ¨æµªæ¼«å–œåŠ‡\n",
    "q_zh = \"æˆ‘æƒ³çœ‹ä¸€éƒ¨æµªæ¼«å–œåŠ‡\"  # ä¸­æ–‡æŸ¥è©¢\n",
    "\n",
    "q_en_embedding = embedder.encode(q_en)\n",
    "q_zh_embedding = embedder.encode(q_zh)\n",
    "print(len(q_en_embedding), len(q_zh_embedding))  # é¡¯ç¤ºåµŒå…¥å‘é‡çš„ç¶­åº¦\n",
    "print(q_en_embedding[:5], q_zh_embedding[:5])  # é¡¯ç¤ºå‰5å€‹ç¶­åº¦å€¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81b838",
   "metadata": {},
   "source": [
    "## æŸ¥è©¢è³‡æ–™åº«ï¼ˆQuerying the databaseï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf600c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¢ç”Ÿä¸€å€‹éš¨æ©Ÿå‘é‡ï¼Œç”¨æ–¼æ¸¬è©¦\n",
    "random_vector = torch.randn(10).numpy()  # ç”¢ç”Ÿä¸€å€‹10ç¶­çš„éš¨æ©Ÿå‘é‡\n",
    "random_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c5018",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "âš ï¸ **è­¦å‘Š**ï¼šä»¥ä¸‹ç¨‹å¼ç¢¼æœƒå¤±æ•—ï¼Œå› ç‚ºéš¨æ©Ÿå‘é‡çš„ç¶­åº¦ (10) èˆ‡è³‡æ–™åº«ä¸­å„²å­˜çš„åµŒå…¥ç¶­åº¦ (384ï¼Œç”± `paraphrase-multilingual-MiniLM-L12-v2` ç”¢ç”Ÿ) ä¸ç¬¦ã€‚ğŸ‘‡\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b2713",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl.search(random_vector).limit(5).to_pandas()  # é€™è¡Œæœƒå ±éŒ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨è‹±æ–‡æŸ¥è©¢å‘é‡é€²è¡Œæœå°‹\n",
    "# .select([\"overview\"]) æŒ‡å®šåªå›å‚³ \"overview\" æ¬„ä½\n",
    "# .limit(5) æŒ‡å®šå›å‚³æœ€ç›¸ä¼¼çš„5ç­†çµæœ\n",
    "# .to_pandas() å°‡çµæœè½‰æ›ç‚º DataFrame\n",
    "tbl.search(q_en_embedding).select([\"overview\"]).limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030739f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ä¸­æ–‡æŸ¥è©¢å‘é‡é€²è¡Œæœå°‹\n",
    "tbl.search(q_zh_embedding).select([\"overview\", \"title\"]).limit(5).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d6750",
   "metadata": {},
   "source": [
    "# å·¥å…·å‘¼å«ï¼ˆFunction callingï¼‰\n",
    "\n",
    "å·¥å…·å‘¼å«ï¼ˆæˆ–ç¨±å‡½å¼å‘¼å«ï¼‰è®“å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰å¯ä»¥èˆ‡å¤–éƒ¨å·¥å…·æˆ– API äº’å‹•ã€‚\n",
    "LLM æœ¬èº«ä¸å…·å‚™åŸ·è¡Œç¨‹å¼ç¢¼æˆ–æŸ¥è©¢è³‡æ–™åº«çš„èƒ½åŠ›ï¼Œä½†é€éå·¥å…·å‘¼å«ï¼Œæˆ‘å€‘å¯ä»¥è³¦äºˆå®ƒé€™äº›èƒ½åŠ›ã€‚\n",
    "\n",
    "æˆ‘å€‘å°‡ä»¥ RAGï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰ä½œç‚ºç¯„ä¾‹ï¼Œå±•ç¤º LLM å¦‚ä½•å‘¼å«æˆ‘å€‘å®šç¾©çš„é›»å½±è³‡æ–™åº«æŸ¥è©¢å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d7210",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# å†æ¬¡ç¢ºèªåµŒå…¥æ¨¡å‹å’Œè³‡æ–™åº«å·²è¼‰å…¥\n",
    "embedder = SentenceTransformer(\n",
    "    \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "    device=\"cpu\",\n",
    ")\n",
    "db = lancedb.connect(\"./data/lance_db\")\n",
    "tbl = db.open_table(\"movies\")  # é–‹å•Ÿ \"movies\" è¡¨æ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c5b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_movie_db(\n",
    "    text: str,\n",
    "    limit: int = 10,\n",
    ") -> ToolCallResult:  # ToolCallResult æ˜¯æˆ‘å€‘è‡ªè¨‚çš„å›å‚³å‹åˆ¥\n",
    "    \"\"\"\n",
    "    æŸ¥è©¢ LanceDB é›»å½±è³‡æ–™åº«ï¼Œæ‰¾å‡ºèˆ‡è¼¸å…¥æ–‡å­—æ¦‚è¦½ç›¸ä¼¼çš„é›»å½±ã€‚\n",
    "\n",
    "    Args:\n",
    "        text (str): ç”¨æ–¼æŸ¥è©¢è³‡æ–™åº«çš„è¼¸å…¥æ–‡å­—ã€‚\n",
    "        limit (int, optional): å›å‚³çµæœçš„æ•¸é‡ï¼Œé è¨­ç‚º 10ã€‚\n",
    "\n",
    "    Returns:\n",
    "        ToolCallResult: åŒ…å«çµ¦ LLM ä½¿ç”¨çš„ JSON å­—ä¸²å’Œçµ¦ UI é¡¯ç¤ºçš„ DataFrameã€‚\n",
    "    \"\"\"\n",
    "    q_emb = embedder.encode(text)  # å°‡æŸ¥è©¢æ–‡å­—è½‰æ›ç‚ºåµŒå…¥\n",
    "    df = (\n",
    "        tbl.search(q_emb)\n",
    "        .limit(limit)\n",
    "        .to_pandas()\n",
    "        .drop(\n",
    "            columns=[\"vector\", \"_distance\"]\n",
    "        )  # ç§»é™¤ \"vector\" å’Œ \"_distance\" æ¬„ä½ï¼Œç°¡åŒ–è¼¸å‡º\n",
    "    )\n",
    "    return {\n",
    "        \"llm_consumable\": df.to_json(\n",
    "            lines=True, orient=\"records\"\n",
    "        ),  # è½‰æ›ç‚º JSON Lines æ ¼å¼ï¼Œæ–¹ä¾¿ LLM è§£æ\n",
    "        \"ui_displayable\": df,  # DataFrame å¯ä»¥ç›´æ¥åœ¨ Jupyter Notebook ä¸­é¡¯ç¤º\n",
    "        \"return_type\": \"dataframe\",  # æ¨™è¨»å›å‚³å‹åˆ¥\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18aede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ query_movie_db å‡½å¼\n",
    "res = query_movie_db(\"air bud\")  # æŸ¥è©¢é—œæ–¼é›»å½± \"air bud\" (ä¸€éš»æœƒæ‰“ç±ƒçƒçš„ç‹—)\n",
    "print(res[\"llm_consumable\"])  # å°å‡ºçµ¦ LLM çš„ JSON å­—ä¸²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f5de0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "res[\"ui_displayable\"].iloc[0]  # é¡¯ç¤ºæŸ¥è©¢çµæœ DataFrame çš„ç¬¬ä¸€ç­†è³‡æ–™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fbd8c3",
   "metadata": {},
   "source": [
    "## å»ºç«‹ JSON çµæ§‹æè¿°ï¼ˆCreating a JSON schemaï¼‰\n",
    "\n",
    "ç‚ºäº†è®“ LLM çŸ¥é“æˆ‘å€‘çš„å·¥å…·æœ‰å“ªäº›åƒæ•¸ã€ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒå€‘ï¼Œæˆ‘å€‘éœ€è¦æä¾›ä¸€å€‹ JSON çµæ§‹æè¿° (JSON Schema)ã€‚\n",
    "Pydantic BaseModel å¯ä»¥æ–¹ä¾¿åœ°å®šç¾©è³‡æ–™çµæ§‹ï¼Œä¸¦è‡ªå‹•ç”¢ç”Ÿ JSON Schemaã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10aab96",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ Pydantic BaseModel å®šç¾© query_movie_db å‡½å¼çš„åƒæ•¸çµæ§‹\n",
    "class QueryMovieDB(BaseModel):\n",
    "    text: str = Field(\n",
    "        description=\"ç”¨ä¾†æŸ¥è©¢é›»å½±æ¦‚è¦½çš„æ–‡å­— (Query overviews of movies)\",\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        default=10,  # é è¨­å€¼\n",
    "        description=\"å›å‚³çµæœçš„æ•¸é‡ (Number of results to return)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99735e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_tool_schema_for_function æ˜¯æˆ‘å€‘åœ¨ utils.py ä¸­å®šç¾©çš„è¼”åŠ©å‡½å¼\n",
    "# å®ƒå¯ä»¥æ ¹æ“šå‡½å¼æœ¬èº«å’Œ Pydanticæ¨¡å‹ç”¢ç”Ÿç¬¦åˆ LLM å·¥å…·å‘¼å«æ ¼å¼çš„ JSON Schema\n",
    "schema = create_tool_schema_for_function(query_movie_db, QueryMovieDB)\n",
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c733bae8",
   "metadata": {},
   "source": [
    "## Hugging Face InferenceClient\n",
    "\n",
    "* [Hugging Face InferenceClient å·¥å…·å‘¼å«æ–‡ä»¶](https://huggingface.co/docs/hugs/en/guides/function-calling)\n",
    "\n",
    "Hugging Face InferenceClient å¯ä»¥è®“æˆ‘å€‘æ–¹ä¾¿åœ°å‘¼å«éƒ¨ç½²åœ¨ Hugging Face æˆ–å…¶ä»–ä¾›æ‡‰å•†ï¼ˆå¦‚ Fireworks AIï¼‰ä¸Šçš„ LLMã€‚\n",
    "æœ‰äº›æ¨¡å‹æ”¯æ´å·¥å…·å‘¼å«åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.getenv(\"HF_TOKEN\")  # å¾ç’°å¢ƒè®Šæ•¸è®€å– Hugging Face API Token\n",
    "if hf_token is None and userdata:\n",
    "    # å¦‚æœåœ¨ Google Colab ç’°å¢ƒï¼Œå˜—è©¦å¾ userdata å–å¾— Hugging Face API Token\n",
    "    hf_token = userdata.get(\"HF_TOKEN\")\n",
    "if not hf_token:\n",
    "    raise ValueError(\"HF_TOKEN ç’°å¢ƒè®Šæ•¸æœªè¨­å®š\")\n",
    "\n",
    "# åˆå§‹åŒ– AsyncInferenceClient\n",
    "# provider=\"fireworks-ai\" è¡¨ç¤ºæˆ‘å€‘å°‡ä½¿ç”¨ Fireworks AI æä¾›çš„æ¨¡å‹æœå‹™\n",
    "# éœ€è¦æœ‰ Fireworks AI çš„å¸³è™Ÿä¸¦è¨­å®šå¥½ HF_TOKEN (é€šå¸¸èˆ‡ Fireworks AI çš„ API Key ç›¸åŒæˆ–ç›¸é—œ)\n",
    "hf_client = AsyncInferenceClient(\n",
    "    provider=\"fireworks-ai\",  # é€™è£¡æŒ‡å®šä½¿ç”¨ Fireworks AI ä½œç‚ºæ¨¡å‹æä¾›è€…\n",
    "    api_key=hf_token,  # Fireworks AI çš„ API é‡‘é‘°\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafe23c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"ä¸è¦å°æ•¸å€¼åšå‡è¨­ã€‚å¦‚æœéœ€è¦ï¼Œè«‹è¦æ±‚æ¾„æ¸…ã€‚(Don't make assumptions about values. Ask for clarification if needed.)\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"æˆ‘æƒ³çœ‹ä¸€éƒ¨é—œæ–¼ä¸€ä½è¢«è¿«é‡å‡ºæ±Ÿæ¹–çš„é€€ä¼‘åˆºå®¢çš„é›»å½±ã€‚ /no_think (I'd like to watch a movie about a retired assassin who is forced back into the game. /no_think)\",\n",
    "        # \"/no_think\" æ˜¯ä¸€å€‹æç¤ºè©æŠ€å·§ï¼Œæœ‰æ™‚å¯ä»¥è®“æ¨¡å‹æ›´å‚¾å‘æ–¼å‘¼å«å·¥å…·è€Œä¸æ˜¯ç›´æ¥å›ç­”\n",
    "    },\n",
    "]\n",
    "\n",
    "# å‘¼å« LLM\n",
    "# model=\"Qwen/Qwen3-235B-A22B\" æ˜¯ Fireworks AI ä¸Šçš„ä¸€å€‹æ¨¡å‹ï¼Œæ”¯æ´å·¥å…·å‘¼å«\n",
    "# tools=[schema] æä¾›äº†æˆ‘å€‘å®šç¾©çš„ query_movie_db å·¥å…·çš„ JSON Schema\n",
    "# tool_choice=\"auto\" å…è¨±æ¨¡å‹è‡ªè¡Œæ±ºå®šæ˜¯å¦ä»¥åŠå‘¼å«å“ªå€‹å·¥å…·\n",
    "# å…¶ä»–é¸é …: \"required\": å¼·åˆ¶æ¨¡å‹å‘¼å«ä¸€å€‹æˆ–å¤šå€‹å·¥å…·; \"none\": ç¦æ­¢æ¨¡å‹å‘¼å«å·¥å…·\n",
    "response = await hf_client.chat_completion(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",  # é€™è£¡éœ€è¦å¡«å¯« Fireworks AI ä¸Šæ”¯æ´å·¥å…·å‘¼å«çš„æ¨¡å‹ ID\n",
    "    messages=messages,\n",
    "    tools=[schema],  # æä¾›å·¥å…·çš„ schema\n",
    "    tool_choice=\"auto\",\n",
    ")  # type: ignore # å¿½ç•¥å‹åˆ¥æª¢æŸ¥çš„è­¦å‘Š\n",
    "print(response.choices[0].message.tool_calls)  # å°å‡ºæ¨¡å‹æ±ºå®šå‘¼å«çš„å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e262abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®Œæ•´çš„æ¨¡å‹å›è¦†è¨Šæ¯\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4435df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡å‹å›è¦†çš„å·¥å…·å‘¼å«ä¸­çš„å‡½å¼éƒ¨åˆ† (å­—ä¸²æ ¼å¼)\n",
    "str(response.choices[0].message.tool_calls[0].function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2dcd9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# è§£æå¾Œçš„å·¥å…·å‘¼å«å‡½å¼ç‰©ä»¶\n",
    "func = response.choices[0].message.tool_calls[0].function\n",
    "func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905abde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].message.tool_calls[0].id)  # å·¥å…·å‘¼å«çš„å”¯ä¸€ ID\n",
    "print(func.name)  # è¢«å‘¼å«çš„å‡½å¼åç¨± (æ‡‰è©²æ˜¯ \"query_movie_db\")\n",
    "print(json.loads(func.arguments))  # è¢«å‘¼å«çš„å‡½å¼åƒæ•¸ (JSON å­—ä¸²è½‰ç‚º Python å­—å…¸)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2839e597",
   "metadata": {},
   "source": [
    "### ä¸²æµæ¨¡å¼æœ‰é»éº»ç…© (Streaming kind of a hassle)\n",
    "\n",
    "Hugging Face InferenceClient ä¹Ÿæ”¯æ´ä¸²æµæ¨¡å¼ (stream=True)ï¼Œå¯ä»¥é€æ­¥æ¥æ”¶æ¨¡å‹çš„è¼¸å‡ºã€‚\n",
    "ä½†åœ¨å·¥å…·å‘¼å«çš„å ´æ™¯ä¸‹ï¼Œè§£æä¸²æµçš„å·¥å…·å‘¼å«è³‡è¨Šæœƒæ¯”è¼ƒè¤‡é›œï¼Œéœ€è¦æ‰‹å‹•çµ„åˆè¨Šæ¯ç‰‡æ®µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ed111",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await hf_client.chat_completion(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",\n",
    "    messages=messages,\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,  # é–‹å•Ÿä¸²æµæ¨¡å¼\n",
    ")  # type: ignore\n",
    "chunks = []\n",
    "async for chunk in response:\n",
    "    chunks.append(chunk)\n",
    "    print(chunk)  # é€å¡Šå°å‡ºæ”¶åˆ°çš„è¨Šæ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"ä½ æ˜¯ä¸€å€‹æ¨‚æ–¼åŠ©äººçš„åŠ©ç†ã€‚åªåœ¨ä½ ç¢ºå®šéœ€è¦æ™‚æ‰æŸ¥è©¢è³‡æ–™åº«ã€‚(You are a helpful assistant. Only query the database if you are sure it is needed.)\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"æˆ‘æƒ³çœ‹ä¸€éƒ¨é—œæ–¼è¶…ç´šè‹±é›„çš„é›»å½±ã€‚ /no_think (I want to watch a movie about superheroes. /no_think)\",\n",
    "    },\n",
    "]\n",
    "# hf_client.chat.completions.create æ˜¯å¦ä¸€å€‹å‘¼å«èŠå¤©æ¨¡å‹çš„ä»‹é¢ï¼Œç”¨æ³•é¡ä¼¼\n",
    "response = await hf_client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",\n",
    "    messages=messages,\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")  # type: ignore\n",
    "chunks = []\n",
    "async for chunk in response:\n",
    "    chunks.append(chunk)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b2c7b0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## OpenAI\n",
    "\n",
    "* [OpenAI å·¥å…·å‘¼å«æ–‡ä»¶](https://platform.openai.com/docs/guides/function-calling?api-mode=chat)\n",
    "* [æ…·æ…¨çš„å…è²»é¡åº¦ (Generous free tier)](https://platform.openai.com/docs/models/gpt-4.1-nano)\n",
    "\n",
    "OpenAI çš„ API ä¹Ÿæ”¯æ´å·¥å…·å‘¼å«ï¼Œä¸¦ä¸”æ•´åˆå¾—ç›¸ç•¶å¥½ã€‚\n",
    "`gpt-4.1-nano` æ˜¯ä¸€å€‹è¼ƒæ–°çš„ã€å¯èƒ½æœƒæœ‰å…è²»é¡åº¦çš„æ¨¡å‹ (è«‹æŸ¥é–± OpenAI æœ€æ–°æ”¿ç­–)ã€‚\n",
    "\n",
    "![](https://i.ibb.co/JwZtC9px/Screenshot-2025-05-20-235653.png \"GPT-4.1-nano\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9329d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if oai_api_key is None and userdata:\n",
    "    # å¦‚æœåœ¨ Google Colab ç’°å¢ƒï¼Œå˜—è©¦å¾ userdata å–å¾— OpenAI API é‡‘é‘°\n",
    "    oai_api_key = userdata.get(\"OPENAI_API_KEY\")\n",
    "if not oai_api_key:\n",
    "    # å¦‚æœæ²’æœ‰æ‰¾åˆ° OpenAI API é‡‘é‘°ï¼Œå‰‡æ‹‹å‡ºéŒ¯èª¤\n",
    "    raise ValueError(\"OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸æœªè¨­å®š\")\n",
    "oai_client = AsyncOpenAI(api_key=oai_api_key)  # åˆå§‹åŒ– OpenAI éåŒæ­¥å®¢æˆ¶ç«¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f75378",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"ä¸è¦å°æ•¸å€¼åšå‡è¨­ã€‚å¦‚æœéœ€è¦ï¼Œè«‹è¦æ±‚æ¾„æ¸…ã€‚\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"æˆ‘æƒ³çœ‹ä¸€éƒ¨é—œæ–¼ä¸€ä½è¢«è¿«é‡å‡ºæ±Ÿæ¹–çš„é€€ä¼‘åˆºå®¢çš„é›»å½±ã€‚\",\n",
    "    },\n",
    "]\n",
    "\n",
    "response = await oai_client.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",  # æˆ–å…¶ä»–æ”¯æ´å·¥å…·å‘¼å«çš„ OpenAI æ¨¡å‹\n",
    "    messages=messages,\n",
    "    tools=[schema],  # åŒæ¨£æä¾›å·¥å…·çš„ JSON Schema\n",
    "    tool_choice=\"auto\",  # è®“æ¨¡å‹è‡ªå‹•æ±ºå®š\n",
    ")\n",
    "print(response.choices[0].message.tool_calls)  # å°å‡ºæ¨¡å‹å›å‚³çš„å·¥å…·å‘¼å«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84963559",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# OpenAI å›å‚³çš„å·¥å…·å‘¼å«ç‰©ä»¶\n",
    "tool_call = response.choices[0].message.tool_calls[0]\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291a5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å»ºç«‹ä¸€å€‹å¯ç”¨çš„å‡½å¼å­—å…¸ï¼Œæ–¹ä¾¿æ ¹æ“šåç¨±å‘¼å«\n",
    "AVAILABLE_FUNCTIONS = {\n",
    "    \"query_movie_db\": query_movie_db,  # å°‡å‡½å¼åç¨±å°æ‡‰åˆ°å¯¦éš›çš„å‡½å¼ç‰©ä»¶\n",
    "}\n",
    "\n",
    "\n",
    "def call_function(name: str, args: dict) -> ToolCallResult:\n",
    "    \"\"\"\n",
    "    æ ¹æ“šå‡½å¼åç¨±å’Œåƒæ•¸å‘¼å«å°æ‡‰çš„å‡½å¼ã€‚\n",
    "    åŒ…å«åŸºæœ¬çš„éŒ¯èª¤è™•ç†ã€‚\n",
    "    \"\"\"\n",
    "    func = AVAILABLE_FUNCTIONS.get(name)\n",
    "    if not func:\n",
    "        # raise ValueError(f\"æœªçŸ¥çš„å‡½å¼ï¼š {name}\")\n",
    "        error_msg = f\"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å·¥å…· '{name}'ã€‚\"\n",
    "        print(error_msg)\n",
    "        return {\n",
    "            \"llm_consumable\": error_msg,\n",
    "            \"ui_displayable\": error_msg,\n",
    "            \"return_type\": \"error_message\",\n",
    "        }\n",
    "    try:\n",
    "        # ä½¿ç”¨ **args å°‡å­—å…¸è§£åŒ…ç‚ºå‡½å¼çš„é—œéµå­—åƒæ•¸\n",
    "        return func(**args)\n",
    "    except TypeError as e:  # æ•æ‰åƒæ•¸ä¸ç¬¦ç­‰ TypeError\n",
    "        error_msg = f\"éŒ¯èª¤ï¼šå‘¼å«å·¥å…· '{name}' æ™‚åƒæ•¸ä¸ç¬¦ï¼Œåƒæ•¸ï¼š{args}ã€‚è©³ç´°è³‡è¨Šï¼š{e}\"\n",
    "        print(error_msg)\n",
    "        return {\n",
    "            \"llm_consumable\": error_msg,\n",
    "            \"ui_displayable\": error_msg,\n",
    "            \"return_type\": \"error_message\",\n",
    "        }\n",
    "    except Exception as e:  # æ•æ‰å·¥å…·åŸ·è¡ŒæœŸé–“çš„å…¶ä»–éŒ¯èª¤\n",
    "        error_msg = f\"éŒ¯èª¤ï¼šåŸ·è¡Œå·¥å…· '{name}' (åƒæ•¸ï¼š{args}) æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚è©³ç´°è³‡è¨Šï¼š{e}\"\n",
    "        print(error_msg)\n",
    "        return {\n",
    "            \"llm_consumable\": error_msg,\n",
    "            \"ui_displayable\": error_msg,\n",
    "            \"return_type\": \"error_message\",\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49994e8",
   "metadata": {},
   "source": [
    "## æª¢æŸ¥ LLM å›æ‡‰ä¸­çš„å·¥å…·å‘¼å«ï¼ˆCheck for function calls in LLM responseï¼‰\n",
    "\n",
    "ç•¶ LLM æ±ºå®šå‘¼å«å·¥å…·æ™‚ï¼Œå®ƒçš„å›æ‡‰æœƒåŒ…å« `tool_calls` æ¬„ä½ã€‚\n",
    "æˆ‘å€‘éœ€è¦ï¼š\n",
    "1.  æª¢æŸ¥ `tool_calls` æ˜¯å¦å­˜åœ¨ã€‚\n",
    "2.  å¦‚æœå­˜åœ¨ï¼Œè§£æå·¥å…·å‘¼å«çš„è³‡è¨Šï¼ˆåç¨±ã€åƒæ•¸ï¼‰ã€‚\n",
    "3.  åŸ·è¡Œå°æ‡‰çš„å·¥å…·å‡½å¼ã€‚\n",
    "4.  å°‡å·¥å…·å‡½å¼çš„åŸ·è¡Œçµæœå›å‚³çµ¦ LLMï¼Œè®“å®ƒå¯ä»¥æ ¹æ“šçµæœç¹¼çºŒç”Ÿæˆå›æ‡‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fc7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncInferenceClient(provider=\"fireworks-ai\", api_key=hf_token)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Don't make assumptions about values. Ask for clarification if needed.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'd like to watch a movie about a retired assassin who is forced back into the game. /no_think\",  # ä¸è¦è®“æ¨¡å‹æ€è€ƒ\n",
    "    },\n",
    "]\n",
    "\n",
    "# å‘¼å« LLM çš„ chat_completion API\n",
    "# model: æŒ‡å®šè¦ä½¿ç”¨çš„ LLM æ¨¡å‹åç¨±\n",
    "# messages: åŒ…å«å®Œæ•´å°è©±æ­·å²çš„è¨Šæ¯åˆ—è¡¨\n",
    "# tools: æä¾›çµ¦ LLM çš„å¯ç”¨å·¥å…·çš„çµæ§‹æè¿°åˆ—è¡¨\n",
    "# tool_choice: \"auto\" è¡¨ç¤ºè®“ LLM è‡ªè¡Œæ±ºå®šæ˜¯å¦ä»¥åŠå‘¼å«å“ªå€‹å·¥å…·\n",
    "# stream=True è¢«è¨»è§£æ‰äº†ï¼Œè¡¨ç¤ºç›®å‰ä¸ä½¿ç”¨ä¸²æµæ¨¡å¼ã€‚ä¸²æµæ¨¡å¼ä¸‹è™•ç†å·¥å…·å‘¼å«æœƒæ¯”è¼ƒè¤‡é›œã€‚\n",
    "response = await client.chat_completion(  # type: ignore # å¿½ç•¥å‹åˆ¥æª¢æŸ¥å™¨çš„è­¦å‘Š\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",  # ä½¿ç”¨ Fireworks AI ä¸Šçš„ Qwen æ¨¡å‹\n",
    "    messages=messages,\n",
    "    tools=[schema],\n",
    "    tool_choice=\"auto\",\n",
    "    # stream=True,  # streaming is a lot of work to handle tool calls and regular messages\n",
    ")  # type: ignore\n",
    "\n",
    "\n",
    "# å¾ LLM çš„å›æ‡‰ä¸­å–å¾—å·¥å…·å‘¼å«çš„è³‡è¨Š\n",
    "# response.choices[0].message æ˜¯ LLM çš„ä¸»è¦å›è¦†å…§å®¹\n",
    "# .tool_calls å¯èƒ½åŒ…å«ä¸€å€‹æˆ–å¤šå€‹æ¨¡å‹æ±ºå®šå‘¼å«çš„å·¥å…·\n",
    "tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "# æª¢æŸ¥ LLM æ˜¯å¦çœŸçš„è¦æ±‚å‘¼å«å·¥å…·\n",
    "if tool_calls:\n",
    "    # å‡è¨­åªè™•ç†ç¬¬ä¸€å€‹å·¥å…·å‘¼å« (å¦‚æœæ¨¡å‹å¯èƒ½ä¸€æ¬¡å‘¼å«å¤šå€‹ï¼Œé€™è£¡éœ€è¦è¿´åœˆè™•ç†)\n",
    "    tc: ChatCompletionOutputToolCall = tool_calls[0]\n",
    "    # è¨˜éŒ„è¢«å‘¼å«çš„å·¥å…·è³‡è¨Š\n",
    "\n",
    "    # å–å¾—å·¥å…·å‘¼å«çš„å”¯ä¸€ ID (call_id)ï¼Œç¨å¾Œå°‡å·¥å…·åŸ·è¡Œçµæœå‚³å›çµ¦ LLM æ™‚æœƒç”¨åˆ°\n",
    "    call_id = tc.id\n",
    "    # å–å¾—è¢«å‘¼å«çš„å‡½å¼åç¨±\n",
    "    func_name = tc.function.name\n",
    "    # è§£æ LLM æä¾›çš„å‡½å¼åƒæ•¸ (å¾ JSON å­—ä¸²è½‰æ›ç‚º Python å­—å…¸)\n",
    "    func_args = json.loads(tc.function.arguments)\n",
    "\n",
    "    # å¯¦éš›åŸ·è¡Œå·¥å…·å‡½å¼\n",
    "    # call_function æ˜¯æˆ‘å€‘è‡ªå·±å®šç¾©çš„å‡½å¼ï¼Œå®ƒæœƒæ ¹æ“š func_name å’Œ func_args åŸ·è¡Œå°æ‡‰çš„å·¥å…·\n",
    "    tool_result = call_function(func_name, func_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea414e",
   "metadata": {},
   "source": [
    "# çµæ§‹åŒ–è¼¸å‡ºï¼ˆStructured outputsï¼‰\n",
    "\n",
    "æœ‰æ™‚å€™ï¼Œæˆ‘å€‘å¸Œæœ› LLM çš„è¼¸å‡ºéµå¾ªç‰¹å®šçš„æ ¼å¼ï¼Œä¾‹å¦‚ JSONã€‚\n",
    "çµæ§‹åŒ–è¼¸å‡ºå¯ä»¥è®“æˆ‘å€‘æ›´å®¹æ˜“åœ°è§£æå’Œä½¿ç”¨ LLM çš„å›æ‡‰ã€‚\n",
    "\n",
    "æˆ‘å€‘å¯ä»¥ä½¿ç”¨ Pydantic BaseModel ä¾†å®šç¾©æœŸæœ›çš„è¼¸å‡ºçµæ§‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StrEnum æ˜¯ Python 3.11+ çš„åŠŸèƒ½ï¼Œç¹¼æ‰¿è‡ª str å’Œ Enumï¼Œè®“åˆ—èˆ‰æˆå“¡æœ¬èº«å°±æ˜¯å­—ä¸²\n",
    "class Polarity(StrEnum):\n",
    "    POSITIVE = \"positive\"\n",
    "    NEGATIVE = \"negative\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "\n",
    "\n",
    "class SentimentAnalysisOutput(BaseModel):\n",
    "    # Annotated å¯ä»¥ç‚ºæ¬„ä½åŠ ä¸Šé¡å¤–çš„æè¿°æˆ–é™åˆ¶\n",
    "    polarity: Annotated[Polarity, \"æ–‡å­—çš„æƒ…æ„Ÿæ¥µæ€§ (The sentiment polarity of the text)\"]\n",
    "    confidence: Annotated[\n",
    "        float,\n",
    "        Field(\n",
    "            description=\"æƒ…æ„Ÿæ¥µæ€§çš„ä¿¡è³´åˆ†æ•¸ï¼Œä»‹æ–¼ 0 å’Œ 1 ä¹‹é–“ (The confidence score of the sentiment polarity between 0 and 1)\",\n",
    "            ge=0.0,  # ge: greater than or equal to (å¤§æ–¼ç­‰æ–¼)\n",
    "            le=1.0,  # le: less than or equal to (å°æ–¼ç­‰æ–¼)\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "# SentimentAnalysisOutput.model_json_schema() å¯ä»¥ç”¢ç”Ÿæ­¤ Pydantic æ¨¡å‹çš„ JSON Schema\n",
    "print(json.dumps(SentimentAnalysisOutput.model_json_schema(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é€™è£¡æœƒæ‹‹å‡º Pydantic çš„ ValidationErrorï¼Œå› ç‚º confidence=1.1 è¶…å‡ºäº†å®šç¾©çš„ç¯„åœ (le=1.0)\n",
    "try:\n",
    "    SentimentAnalysisOutput(polarity=\"positive\", confidence=1.1)\n",
    "except Exception as e:\n",
    "    print(e)  # å°å‡ºéŒ¯èª¤è¨Šæ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab182c7b",
   "metadata": {},
   "source": [
    "## æº–å‚™æç¤ºï¼ˆPrepare promptï¼‰\n",
    "\n",
    "æç¤ºä¸­éœ€è¦æ¸…æ¥šåœ°å‘ŠçŸ¥ LLM æˆ‘å€‘æœŸæœ›çš„ JSON æ ¼å¼ï¼ŒåŒ…å«æ¬„ä½åç¨±å’Œå€¼çš„ç¯„ä¾‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\\\n",
    "è«‹åˆ†æä»¥ä¸‹æ–‡å­—çš„æƒ…æ„Ÿï¼ˆæ­£é¢ã€è² é¢æˆ–ä¸­æ€§ï¼‰ï¼Œä¸¦ä»¥ JSON æ ¼å¼å›å‚³çµæœã€‚\n",
    "JSON æ‡‰åŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š\n",
    "- polarity: æ–‡å­—çš„æƒ…æ„Ÿæ¥µæ€§ï¼ˆpositiveã€negative æˆ– neutralï¼‰\n",
    "- confidence: æƒ…æ„Ÿæ¥µæ€§çš„ä¿¡è³´åˆ†æ•¸ï¼Œä»‹æ–¼ 0ï¼ˆä¸ç¢ºå®šï¼‰å’Œ 1ï¼ˆéå¸¸ç¢ºå®šï¼‰ä¹‹é–“\n",
    "JSON æ ¼å¼æ‡‰å¦‚ä¸‹ï¼š\n",
    "{{\n",
    "    \"polarity\": \"positive\",\n",
    "    \"confidence\": 0.95\n",
    "}}\n",
    "æ–‡å­—ï¼š {text}\n",
    "\"\"\"\n",
    "\n",
    "text_to_analyze = \"é¦™èœåŠ åœ¨ä»»ä½•æ±è¥¿ä¸Šéƒ½è¶…è®šçš„ï¼(Cilantro is amazing on everything!)\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": base_prompt.format(text=text_to_analyze),\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27bda4",
   "metadata": {},
   "source": [
    "## Hugging Face InferenceClient\n",
    "\n",
    "å°æ–¼ Hugging Face InferenceClientï¼Œæˆ‘å€‘éœ€è¦åœ¨ `chat_completion` çš„ `response_format` åƒæ•¸ä¸­æä¾›æœŸæœ›çš„ JSON Schemaã€‚\n",
    "`response_format={\"type\": \"json_object\", \"value\": SCHEMA}`\n",
    "æŸäº›æ¨¡å‹ï¼ˆä¾‹å¦‚è¼ƒæ–°çš„ Qwen æ¨¡å‹ï¼‰æ”¯æ´é€™å€‹åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c6ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await hf_client.chat_completion(\n",
    "    model=\"Qwen/Qwen3-235B-A22B\",  # ç¢ºèªæ­¤æ¨¡å‹æ”¯æ´ JSON æ¨¡å¼å’Œ schema æŒ‡å®š\n",
    "    messages=messages,\n",
    "    response_format={\n",
    "        \"type\": \"json_object\",  # æŒ‡å®šå›å‚³å‹åˆ¥ç‚º JSON ç‰©ä»¶\n",
    "        \"value\": SentimentAnalysisOutput.model_json_schema(),  # æä¾› Pydantic æ¨¡å‹çš„ JSON Schema\n",
    "    },\n",
    ")  # type: ignore\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51fbcae",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# LLM å›å‚³çš„åŸå§‹ JSON å­—ä¸²å…§å®¹\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8854f6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# å°‡ JSON å­—ä¸²è§£æç‚º Python å­—å…¸\n",
    "response_dict = json.loads(response.choices[0].message.content)\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58244de8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ Pydantic æ¨¡å‹é©—è­‰ä¸¦è½‰æ›å­—å…¸\n",
    "# å¦‚æœ response_dict çš„çµæ§‹ç¬¦åˆ SentimentAnalysisOutputï¼Œå‰‡æœƒæˆåŠŸè½‰æ›\n",
    "# å¦å‰‡æœƒæ‹‹å‡º ValidationError\n",
    "sentiment_result = SentimentAnalysisOutput(**response_dict)\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405fcc1d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Pydantic æ¨¡å‹æä¾›äº† model_validate_json æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥å¾ JSON å­—ä¸²é©—è­‰ä¸¦è½‰æ›\n",
    "sentiment_result = SentimentAnalysisOutput.model_validate_json(\n",
    "    response.choices[0].message.content\n",
    ")\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e948ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# å­˜å– Pydantic ç‰©ä»¶çš„å±¬æ€§\n",
    "str(sentiment_result.polarity)  # .polarity æ˜¯ Polarity åˆ—èˆ‰å‹åˆ¥ï¼Œstr() å¯ä»¥å–å¾—å…¶å­—ä¸²å€¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd4739",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "\n",
    "[OpenAI çµæ§‹åŒ–è¼¸å‡ºæ–‡ä»¶](https://platform.openai.com/docs/guides/structured-outputs?api-mode=chat)\n",
    "\n",
    "OpenAI çš„ Python SDK æä¾›äº†æ›´æ–¹ä¾¿çš„æ–¹å¼ä¾†è™•ç†çµæ§‹åŒ–è¼¸å‡ºã€‚\n",
    "å¯ä»¥ç›´æ¥å°‡ Pydantic æ¨¡å‹å‚³éçµ¦ `response_format` åƒæ•¸ (ä½¿ç”¨ `openai.beta.chat.completions.parse` æ™‚)ã€‚\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "âš ï¸ **æ³¨æ„**ï¼šæˆ‘å€‘ä½¿ç”¨ `client.beta.chat.completions.parse` è€Œä¸æ˜¯ `client.chat.completions.create`ã€‚\n",
    "`parse` æ–¹æ³•æœƒè‡ªå‹•è™•ç† JSON è§£æä¸¦é©—è­‰ Pydantic æ¨¡å‹ã€‚\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ client.beta.chat.completions.parse\n",
    "# å°‡ Pydantic æ¨¡å‹ SentimentAnalysisOutput ç›´æ¥å‚³çµ¦ response_format\n",
    "response = await oai_client.beta.chat.completions.parse(\n",
    "    messages=messages,\n",
    "    model=\"gpt-4.1-nano\",  # æˆ–å…¶ä»–æ”¯æ´ JSON æ¨¡å¼çš„ OpenAI æ¨¡å‹\n",
    "    response_format=SentimentAnalysisOutput,  # ç›´æ¥å‚³é Pydantic æ¨¡å‹\n",
    ")\n",
    "response  # response ç‰©ä»¶æœ¬èº«å°±åŒ…å«äº† .parsed çš„çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e07ad",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# LLM å›å‚³çš„åŸå§‹ JSON å­—ä¸²å…§å®¹ (å¦‚æœéœ€è¦æŸ¥çœ‹)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2c76c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# å¦‚æœéœ€è¦æ‰‹å‹•è§£æ (é›–ç„¶ parse æ–¹æ³•å·²ç¶“åšäº†)\n",
    "response_dict = json.loads(response.choices[0].message.content)\n",
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746eb601",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ Pydantic æ¨¡å‹é©—è­‰ä¸¦è½‰æ›å­—å…¸\n",
    "sentiment_result = SentimentAnalysisOutput(**response_dict)\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95824e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Pydantic æ¨¡å‹æä¾›äº† model_validate_json æ–¹æ³•\n",
    "sentiment_result = SentimentAnalysisOutput.model_validate_json(\n",
    "    response.choices[0].message.content\n",
    ")\n",
    "sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3cf984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›´æ¥å­˜å– .parse() æ–¹æ³•è§£æå¥½çš„ Pydantic ç‰©ä»¶\n",
    "# é€™æ˜¯ä½¿ç”¨ .beta.chat.completions.parse çš„ä¸»è¦å„ªé»\n",
    "parsed_output = response.choices[0].message.parsed\n",
    "print(parsed_output)\n",
    "print(type(parsed_output))  # å‹åˆ¥æ‡‰è©²æ˜¯ <class '__main__.SentimentAnalysisOutput'>\n",
    "print(parsed_output.polarity)\n",
    "print(parsed_output.confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47016b38",
   "metadata": {},
   "source": [
    "# èŠå¤©æ©Ÿå™¨äººï¼ˆChatbotï¼‰\n",
    "\n",
    "[Creating a chatbot fast](https://www.gradio.app/guides/creating-a-chatbot-fast)\n",
    "\n",
    "è‹¥è¦ä½¿ç”¨ `gr.ChatInterface()` å»ºç«‹èŠå¤©æ‡‰ç”¨ç¨‹å¼ï¼Œæ‚¨é¦–å…ˆæ‡‰è©²åšçš„æ˜¯å®šç¾©æ‚¨çš„èŠå¤©å‡½æ•¸ ã€‚æœ€ç°¡å–®çš„æƒ…æ³ä¸‹ï¼Œæ‚¨çš„èŠå¤©å‡½æ•¸æ‡‰æ¥å—å…©å€‹åƒæ•¸ï¼š`message` å’Œ `history`ï¼ˆåƒæ•¸åç¨±å¯ä»¥è‡ªè¨‚ï¼Œä½†å¿…é ˆä¾ç…§æ­¤é †åºï¼‰ã€‚\n",
    "\n",
    "* `message`ï¼šä¸€å€‹ `str`ï¼Œä»£è¡¨ä½¿ç”¨è€…æœ€è¿‘çš„è¨Šæ¯ã€‚\n",
    "* `history`ï¼šä¸€å€‹ OpenAI é¢¨æ ¼çš„å­—å…¸åˆ—è¡¨ï¼Œå…¶ä¸­åŒ…å« `role` å’Œ `content` éµï¼Œä»£è¡¨å…ˆå‰çš„å°è©±æ­·å²ã€‚ä¹Ÿå¯èƒ½åŒ…å«ä»£è¡¨è¨Šæ¯å…ƒè³‡æ–™çš„å…¶ä»–éµ ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œ`history` å¯èƒ½å¦‚ä¸‹æ‰€ç¤ºï¼š\n",
    "\n",
    "```json\n",
    "[\n",
    "  {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Paris\"}\n",
    "]\n",
    "```\n",
    "\n",
    "è€Œä¸‹ä¸€å‰‡ `message` å°‡æœƒæ˜¯ï¼š\n",
    "\n",
    "```\n",
    "\"And what is its largest city?\"\n",
    "```\n",
    "\n",
    "æ‚¨çš„èŠå¤©å‡½æ•¸åªéœ€è¦å›å‚³ï¼š\n",
    "\n",
    "ä¸€å€‹ `str` å€¼ï¼Œé€™æ˜¯èŠå¤©æ©Ÿå™¨äººæ ¹æ“šèŠå¤©æ­·å²å’Œæœ€æ–°è¨Šæ¯æ‰€åšçš„å›æ‡‰ï¼Œä¾‹å¦‚ï¼Œåœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼š\n",
    "\n",
    "```\n",
    "Paris is also the largest city.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a8dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "hf_client = AsyncInferenceClient(\n",
    "    provider=\"fireworks-ai\",\n",
    "    api_key=hf_token,\n",
    ")\n",
    "\n",
    "\n",
    "async def hf_chat(message, history) -> str:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ Hugging Face çš„èŠå¤©æ¨¡å‹é€²è¡Œå°è©±ã€‚\n",
    "    \"\"\"\n",
    "    response = await hf_client.chat_completion(\n",
    "        model=\"Qwen/Qwen3-235B-A22B\",\n",
    "        messages=history + [{\"role\": \"user\", \"content\": message}],\n",
    "    )  # type: ignore\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "oai_client = AsyncOpenAI(api_key=oai_api_key)\n",
    "\n",
    "\n",
    "async def oai_chat(message, history) -> str:\n",
    "    response = await oai_client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=history + [{\"role\": \"user\", \"content\": message}],\n",
    "    )  # type: ignore\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=hf_chat,  # ä½¿ç”¨ Hugging Face çš„èŠå¤©æ¨¡å‹\n",
    "    title=\"Chat with Qwen\",  # æ¨™é¡Œ\n",
    "    type=\"messages\",\n",
    ").launch(share=True)  # å•Ÿå‹• Gradio ä»‹é¢ï¼Œä¸¦åˆ†äº«é€£çµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a68af7",
   "metadata": {},
   "source": [
    "# æ¸¬è©¦æ‡‰ç”¨ç¨‹å¼\n",
    "æ¥ä¸‹ä¾†è¦æ‰“é–‹ [`app.py`](app.py)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
